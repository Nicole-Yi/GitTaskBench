{"model_name_or_path": "deepseek-v3__t-0.00__p-1.00__c-0.00___610ba3", "instance_id": "610ba3", "model_patch": "diff --git a/speaker_verification.py b/speaker_verification.py\nnew file mode 100644\nindex 00000000..de3bac11\n--- /dev/null\n+++ b/speaker_verification.py\n@@ -0,0 +1,28 @@\n+\n+import json\n+from speechbrain.inference.speaker import SpeakerRecognition\n+\n+# Initialize the speaker recognition model\n+verification = SpeakerRecognition.from_hparams(\n+    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n+    savedir=\"/tmp/pretrained_models/spkrec-ecapa-voxceleb\"\n+)\n+\n+# Paths to the input audio files\n+file1 = \"/data/data/agent_test_codebase/GitTaskBench/queries/SpeechBrain_05/input/SpeechBrain_05_input_01.wav\"\n+file2 = \"/data/data/agent_test_codebase/GitTaskBench/queries/SpeechBrain_05/input/SpeechBrain_05_input_02.wav\"\n+\n+# Perform verification\n+score, prediction = verification.verify_files(file1, file2)\n+\n+# Prepare the result\n+result = {\n+    \"prediction\": bool(prediction)\n+}\n+\n+# Save the result to a JSON file\n+output_path = \"/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/SpeechBrain_05/output.json\"\n+with open(output_path, \"w\") as f:\n+    json.dump(result, f)\n+\n+print(f\"Result saved to {output_path}\")\n\\ No newline at end of file\n"}