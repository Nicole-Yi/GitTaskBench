2025-05-12 13:20:47,181 - INFO - swea-run - Starting environment
2025-05-12 13:20:47,220 - INFO - rex-deploy - Starting container 3eb72bc4a848-e1365632-4b86-43e1-b1e1-d69502160e2d with image 3eb72bc4a848 serving on port 53313
2025-05-12 13:20:47,232 - INFO - rex-deploy - Starting runtime at 53313
2025-05-12 13:20:48,510 - INFO - rex-deploy - Runtime started in 1.28s
2025-05-12 13:20:49,284 - INFO - swea-env - Environment Initialized
2025-05-12 13:22:56,787 - INFO - swea-run - Running agent
2025-05-12 13:22:56,800 - INFO - swea-agent - Setting up agent for instance 2dc60e
2025-05-12 13:22:56,801 - INFO - swea-agent - Trajectory will be saved to /data/code/agent_new/SWE-agent/trajectories/i-youwang/default__openai/deepseek-v3__t-0.00__p-1.00__c-0.00___2dc60e/2dc60e/2dc60e.traj
2025-05-12 13:23:02,220 - INFO - swea-tools - Resetting tools
2025-05-12 13:23:02,687 - INFO - swea-agent - SYSTEM (main)
SETTING: You are an autonomous programmer, and you're working directly in the command line with a special interface.

The special interface consists of a file editor that shows you 100 lines of a file at a time.
In addition to typical bash commands, you can also use specific commands to help you navigate and edit files.
To call a command, you need to invoke it with a function call/tool call.

Please note that THE EDIT COMMAND REQUIRES PROPER INDENTATION.

For example, if you are looking at this file:

def fct():
    print("Hello world")

and you want to edit the file to read:

def fct():
    print("Hello")
    print("world")

you search string should be `Hello world` and your replace string should be `"Hello"\n    print("world")`
(note the extra spaces before the print statement!).

You could also get the same result by search for `    print("Hello world")` and replace with `    print("Hello")\n    print("world")`.

RESPONSE FORMAT:
Your shell prompt is formatted as follows:
(Open file: <path>)
(Current directory: <cwd>)
bash-$

First, you should _always_ include a general thought about what you're going to do next.
Then, for every response, you must include exactly _ONE_ tool call/function call.

Remember, you should always include a _SINGLE_ tool call/function call and then wait for a response from the shell before continuing with more discussion and commands. Everything you include in the DISCUSSION section will be saved for future reference.
If you'd like to issue two commands at once, PLEASE DO NOT DO THAT! Please instead first submit just the first tool call, and then after receiving a response you'll be able to issue the second .
Note that the environment does NOT support interactive session commands (e.g. python, vim), so please do not invoke them.
2025-05-12 13:23:02,694 - INFO - swea-agent - DEMONSTRATION: /data/code/agent_new/SWE-agent/trajectories/demonstrations/replay__marshmallow-code__marshmallow-1867__function_calling_replace__install-1/marshmallow-code__marshmallow-1867.traj
2025-05-12 13:23:02,851 - INFO - swea-agent - 🤖 MODEL INPUT
We're currently solving the following issue within our repository. Here's the issue text:
ISSUE:

## 任务描述
从给定的仓库列表中选取合适的仓库，实现语音识别功能，输出音频的文字内容

## 可用仓库
仓库名称: FunASR
仓库路径 (绝对): /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
理解指南: ['阅读README.md了解项目基本功能和使用方法']

## 文件路径
输入：
文件路径 (绝对): /data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav
文件描述: 需要识别的语音文件

输出：
输出文件目录:/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01, 如果只有一个文件，就以 `output` 命名; 如果存在多个以 `output_01`开始命名，格式根据需求指定。

## 补充说明
**核心目标**: 快速理解和分析代码仓库，生成并执行必要的代码或调用工具，以高效、准确地完成用户指定的任务。

## 工作流程与规范

1.  **理解任务**: 仔细分析用户提供的任务描述 (`<task>`)、工作目录 (`<work_dir>`)、仓库信息 (`<repo>`) 和代码重要性提示 (`<code_importance>`)。
2.  **规划方案**: 
    *   如果没有现成计划，先制定清晰的执行步骤。请先阅读代码库的README.md文件，了解代码库的结构和使用方法。
    *   如果没有README.md文件或者README.md文件中没有提供足够信息，请先阅读代码库的代码，了解代码库的结构和使用方法。
    *   明确哪些步骤需要编写代码，哪些步骤依赖语言理解和工具调用。
    *   代码生成和执行过程中，涉及到路径的请使用绝对路径，不要使用相对路径，以免出现路径错误。
3.  **代码库分析**: 
    *   **探索结构**: 快速了解仓库的整体文件和目录结构, 请使用绝对路径。
    *   **识别关键文件**: 优先关注 `README.md`, 配置文件, 主入口脚本等。
    *   **依赖管理**: 
        *   检查 `requirements.txt` 或类似文件，确定所需依赖。
        *   **如果需要安装依赖**：在代码块中包含安装命令 (e.g., `pip install -r requirements.txt` 或 `pip install specific_package`)。检查包是否存在避免重复安装。
        *   **不要使用conda install，请使用pip install**。
        *   **环境配置**: Python/Conda环境已预设，无需额外配置。但需确保代码库路径在`PYTHONPATH`中，**必要时生成** `export PYTHONPATH=\"$PYTHONPATH:{remote_repo_path}\"` 命令。
4. 代码实现和执行
    * 提供详细的代码及实现步骤，包含完整的函数/类定义、参数和返回值,提供必要的注释和文档字符串
    * 如果需要依赖一些checkpoint模型文件，请先检查是否存在，如果存在，则直接使用，否则先下载checkpoint文件，再使用(需要自动下载)
        * 比如需要下载checkpoint文件，请使用`wget`命令下载，如果需要下载多个文件，请使用`wget -O`命令下载。

5.  **错误处理与迭代**: 
    *   检查代码执行结果。
    *   如果出现错误，分析原因，**修复代码**并重新生成**完整**脚本进行尝试。
    *   如果多次尝试后仍无法解决或任务无法完成，分析原因并考虑替代方案。
6.  **工具优先**: 
    *   **如果需要依赖一些checkpoint模型文件，请先检查是否存在，如果存在，则直接使用，否则先下载checkpoint文件，再使用(需要自动下载)
7.  **任务完成**: 
    *   当任务成功完成，或确认无法完成时，提供清晰的总结。

## !! 关键约束与强制要求 !!

*   **绝对路径**: 在代码中处理文件（特别是数据加载）时，**必须**使用**绝对路径**。
*   **提供的仓库 > 代码**: 现有仓库代码能完成的任务，**严禁**自行重新编写代码实现。
*   **请先阅读代码库的README.md文件，了解代码库的结构和使用方法**。如果没有README.md文件或者README.md文件中没有提供足够信息，请先阅读代码库的代码，了解代码库的结构和使用方法。

** 执行前首先运行 `eval $(curl -s http://deploy.i.shaipower.com/httpproxy)`

INSTRUCTIONS:
Now, you're going to solve this issue on your own. Your terminal session has started and you're in the repository's root directory. You can use any bash commands or the special interface to help you. Edit all the files you need to and run any checks or tests that you want.
Remember, YOU SHOULD ALWAYS INCLUDE EXACTLY ONE TOOL CALL/FUNCTION CALL PER RESPONSE.
When you're satisfied with all of the changes you've made, you can submit your changes to the code base by simply running the submit command.
Note however that you cannot use any interactive session commands (e.g. python, vim) in this environment, but you can write scripts and run them. E.g. you can write a python script and then run it with the python command.

NOTE ABOUT THE EDIT COMMAND: Indentation really matters! When editing a file, make sure to insert appropriate indentation before each line!

GENERAL IMPORTANT TIPS:

1. If you run a command and it doesn't work, try running a different command. A command that did not work once will not work the second time unless you modify it!

2. If you open a file and need to get to an area around a specific line that is not in the first 100 lines, say line 583, don't just use the scroll_down command multiple times. Instead, use the goto 583 command. It's much quicker.

3. If the bug reproduction script requires inputting/reading a specific file, such as buggy-input.png, and you'd like to understand how to input that file, conduct a search in the existing repo code, to see whether someone else has already done that. Do this by running the command: find_file "buggy-input.png" If that doesn't work, use the linux 'find' command.

4. Always make sure to look at the currently open file and the current working directory (which appears right after the currently open file). The currently open file might be in a different directory than the working directory! Note that some commands, such as 'create', open files, so they might change the current open file.

5. When editing files, it is easy to accidentally to write code with incorrect indentation or make other mistakes. Always check the code after you issue an edit to make sure that it reflects what you wanted to accomplish. If it didn't, issue another command to fix it.

6. When editing files, first explain the code you want to edit and why it is causing the problem. Then explain the edit you want to make and how it fixes the problem. Explain how the edit does not break existing functionality.

7. Do not try to install any packages with `pip`, `conda`, or any other way. This will usually not work. If the environment is not set up correctly, try to fix the issue without executing python code or running any tests that require the package installed.

STRATEGY:

1. Always start by trying to replicate the bug that the issues discusses.
  If the issue includes code for reproducing the bug, we recommend that you re-implement that in your environment, and run it to make sure you can reproduce the bug.
  Then start trying to fix it.

  If the bug reproduction script does not print anything when it successfully runs, we recommend adding a print("Script completed successfully, no errors.") command at the end of the file,
  so that you can be sure that the script indeed ran fine all the way through.

2. Locate relevant code using the find and search commands. `open` the file you want to edit.

3. Use the `edit` command to perform edits.

4. When you think you've fixed the bug, re-run the bug reproduction script to make sure that the bug has indeed been fixed.

5. Create additional tests to verify the fix in a style similar to the existing reproduction script. In particular, make sure to test edge cases.
   If you find any issues, go back to the file you edited and perform further edits.

(Open file: n/a)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:23:02,859 - INFO - swea-agent - ========================= STEP 1 =========================
2025-05-12 13:23:02,868 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:23:13,796 - INFO - swea-lm - Response: ModelResponse(id='021747027382972012d362c6c478fde46ec9847587ba156374d01', created=1747027393, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="To solve this task, we need to use the FunASR repository to perform speech recognition on the provided audio file (`FunASR_01_input.wav`) and save the output text in the specified directory. \n\n### Steps to Follow:\n1. **Understand the FunASR Repository**: First, we need to explore the FunASR repository to understand its structure and how to use it for speech recognition.\n2. **Locate the Input File**: Identify the absolute path of the input audio file.\n3. **Run Speech Recognition**: Use the FunASR tool to process the audio file and generate the output text.\n4. **Save the Output**: Save the recognized text to the specified output directory.\n\n### Next Step:\nFirst, let's explore the FunASR repository to locate the relevant scripts or documentation (e.g., `README.md`) that explain how to use the repository for speech recognition.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"path":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md"}', name='open'), id='call_r92koak63bu4zhpbptkkrdle', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=221, prompt_tokens=11595, total_tokens=11816, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:23:13,808 - INFO - swea-agent - 💭 THOUGHT
To solve this task, we need to use the FunASR repository to perform speech recognition on the provided audio file (`FunASR_01_input.wav`) and save the output text in the specified directory. 

### Steps to Follow:
1. **Understand the FunASR Repository**: First, we need to explore the FunASR repository to understand its structure and how to use it for speech recognition.
2. **Locate the Input File**: Identify the absolute path of the input audio file.
3. **Run Speech Recognition**: Use the FunASR tool to process the audio file and generate the output text.
4. **Save the Output**: Save the recognized text to the specified output directory.

### Next Step:
First, let's explore the FunASR repository to locate the relevant scripts or documentation (e.g., `README.md`) that explain how to use the repository for speech recognition.

🎬 ACTION
open "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md"
2025-05-12 13:23:14,329 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md (391 lines total)]
1:[//]: # (<div align="left"><img src="docs/images/funasr_logo.jpg" width="400"/></div>)
2:
3:([简体中文](./README_zh.md)|English)
4:
5:[//]: # (# FunASR: A Fundamental End-to-End Speech Recognition Toolkit)
6:
7:[![SVG Banners](https://svg-banners.vercel.app/api?type=origin&text1=FunASR🤠&text2=💖%20A%20Fundamental%20End-to-End%20Speech%20Recognition%20Toolkit&width=800&height=210)](https://github.com/Akshay090/svg-banners)
8:
9:[![PyPI](https://img.shields.io/pypi/v/funasr)](https://pypi.org/project/funasr/)
10:
11:<p align="center">
12:<a href="https://trendshift.io/repositories/3839" target="_blank"><img src="https://trendshift.io/api/badge/repositories/3839" alt="alibaba-damo-academy%2FFunASR | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>
13:</p>
14:
15:<strong>FunASR</strong> hopes to build a bridge between academic research and industrial applications on speech recognition. By supporting the training & finetuning of the industrial-grade speech recognition model, researchers and developers can conduct research and production of speech recognition models more conveniently, and promote the development of speech recognition ecology. ASR for Fun！
16:
17:[**Highlights**](#highlights)
18:| [**News**](https://github.com/alibaba-damo-academy/FunASR#whats-new) 
19:| [**Installation**](#installation)
20:| [**Quick Start**](#quick-start)
21:| [**Tutorial**](https://github.com/alibaba-damo-academy/FunASR/blob/main/docs/tutorial/README.md)
22:| [**Runtime**](./runtime/readme.md)
23:| [**Model Zoo**](#model-zoo)
24:| [**Contact**](#contact)
25:
26:
27:
28:
29:<a name="highlights"></a>
30:## Highlights
31:- FunASR is a fundamental speech recognition toolkit that offers a variety of features, including speech recognition (ASR), Voice Activity Detection (VAD), Punctuation Restoration, Language Models, Speaker Verification, Speaker Diarization and multi-talker ASR. FunASR provides convenient scripts and tutorials, supporting inference and fine-tuning of pre-trained models.
32:- We have released a vast collection of academic and industrial pretrained models on the [ModelScope](https://www.modelscope.cn/models?page=1&tasks=auto-speech-recognition) and [huggingface](https://huggingface.co/FunASR), which can be accessed through our [Model Zoo](https://github.com/alibaba-damo-academy/FunASR/blob/main/docs/model_zoo/modelscope_models.md). The representative [Paraformer-large](https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary), a non-autoregressive end-to-end speech recognition model, has the advantages of high accuracy, high efficiency, and convenient deployment, supporting the rapid construction of speech recognition services. For more details on service deployment, please refer to the [service deployment document](runtime/readme_cn.md). 
33:
34:
35:<a name="whats-new"></a>
36:## What's new:
37:- 2024/10/29: Real-time Transcription Service 1.12 released, The 2pass-offline mode supports the SensevoiceSmal model；([docs](runtime/readme.md));
38:- 2024/10/10：Added support for the Whisper-large-v3-turbo model, a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. It can be downloaded from the [modelscope](examples/industrial_data_pretraining/whisper/demo.py), and [openai](examples/industrial_data_pretraining/whisper/demo_from_openai.py).
39:- 2024/09/26: Offline File Transcription Service 4.6, Offline File Transcription Service of English 1.7, Real-time Transcription Service 1.11 released, fix memory leak & Support the SensevoiceSmall onnx model；File Transcription Service 2.0 GPU released, Fix GPU memory leak; ([docs](runtime/readme.md));
40:- 2024/09/25：keyword spotting models are new supported. Supports fine-tuning and inference for four models: [fsmn_kws](https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online), [fsmn_kws_mt](https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online), [sanm_kws](https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-offline), [sanm_kws_streaming](https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online).
41:- 2024/07/04：[SenseVoice](https://github.com/FunAudioLLM/SenseVoice) is a speech foundation model with multiple speech understanding capabilities, including ASR, LID, SER, and AED.
42:- 2024/07/01: Offline File Transcription Service GPU 1.1 released, optimize BladeDISC model compatibility issues; ref to ([docs](runtime/readme.md))
43:- 2024/06/27: Offline File Transcription Service GPU 1.0 released, supporting dynamic batch processing and multi-threading concurrency. In the long audio test set, the single-thread RTF is 0.0076, and multi-threads' speedup is 1200+ (compared to 330+ on CPU); ref to ([docs](runtime/readme.md))
44:- 2024/05/15：emotion recognition models are new supported. [emotion2vec+large](https://modelscope.cn/models/iic/emotion2vec_plus_large/summary)，[emotion2vec+base](https://modelscope.cn/models/iic/emotion2vec_plus_base/summary)，[emotion2vec+seed](https://modelscope.cn/models/iic/emotion2vec_plus_seed/summary). currently supports the following categories: 0: angry 1: happy 2: neutral 3: sad 4: unknown.
45:- 2024/05/15: Offline File Transcription Service 4.5, Offline File Transcription Service of English 1.6, Real-time Transcription Service 1.10 released, adapting to FunASR 1.0 model structure；([docs](runtime/readme.md))
46:
47:<details><summary>Full Changelog</summary>
48:
49:- 2024/03/05：Added the Qwen-Audio and Qwen-Audio-Chat large-scale audio-text multimodal models, which have topped multiple audio domain leaderboards. These models support speech dialogue, [usage](examples/industrial_data_pretraining/qwen_audio).
50:- 2024/03/05：Added support for the Whisper-large-v3 model, a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. It can be downloaded from the[modelscope](examples/industrial_data_pretraining/whisper/demo.py), and [openai](examples/industrial_data_pretraining/whisper/demo_from_openai.py).
51:- 2024/03/05: Offline File Transcription Service 4.4, Offline File Transcription Service of English 1.5，Real-time Transcription Service 1.9 released，docker image supports ARM64 platform, update modelscope；([docs](runtime/readme.md))
52:- 2024/01/30：funasr-1.0 has been released ([docs](https://github.com/alibaba-damo-academy/FunASR/discussions/1319))
53:- 2024/01/30：emotion recognition models are new supported. [model link](https://www.modelscope.cn/models/iic/emotion2vec_base_finetuned/summary), modified from [repo](https://github.com/ddlBoJack/emotion2vec).
54:- 2024/01/25: Offline File Transcription Service 4.2, Offline File Transcription Service of English 1.3 released，optimized the VAD (Voice Activity Detection) data processing method, significantly reducing peak memory usage, memory leak optimization; Real-time Transcription Service 1.7 released，optimizatized the client-side；([docs](runtime/readme.md))
55:- 2024/01/09: The Funasr SDK for Windows version 2.0 has been released, featuring support for The offline file transcription service (CPU) of Mandarin 4.1, The offline file transcription service (CPU) of English 1.2, The real-time transcription service (CPU) of Mandarin 1.6. For more details, please refer to the official documentation or release notes([FunASR-Runtime-Windows](https://www.modelscope.cn/models/damo/funasr-runtime-win-cpu-x64/summary))
56:- 2024/01/03: File Transcription Service 4.0 released, Added support for 8k models, optimized timestamp mismatch issues and added sentence-level timestamps, improved the effectiveness of English word FST hotwords, supported automated configuration of thread parameters, and fixed known crash issues as well as memory leak problems, refer to ([docs](runtime/readme.md#file-transcription-service-mandarin-cpu)).
57:- 2024/01/03: Real-time Transcription Service 1.6 released，The 2pass-offline mode supports Ngram language model decoding and WFST hotwords, while also addressing known crash issues and memory leak problems, ([docs](runtime/readme.md#the-real-time-transcription-service-mandarin-cpu))
58:- 2024/01/03: Fixed known crash issues as well as memory leak problems, ([docs](runtime/readme.md#file-transcription-service-english-cpu)).
59:- 2023/12/04: The Funasr SDK for Windows version 1.0 has been released, featuring support for The offline file transcription service (CPU) of Mandarin, The offline file transcription service (CPU) of English, The real-time transcription service (CPU) of Mandarin. For more details, please refer to the official documentation or release notes([FunASR-Runtime-Windows](https://www.modelscope.cn/models/damo/funasr-runtime-win-cpu-x64/summary))
60:- 2023/11/08: The offline file transcription service 3.0 (CPU) of Mandarin has been released, adding punctuation large model, Ngram language model, and wfst hot words. For detailed information, please refer to [docs](runtime#file-transcription-service-mandarin-cpu). 
61:- 2023/10/17: The offline file transcription service (CPU) of English has been released. For more details, please refer to ([docs](runtime#file-transcription-service-english-cpu)).
62:- 2023/10/13: [SlideSpeech](https://slidespeech.github.io/): A large scale multi-modal audio-visual corpus with a significant amount of real-time synchronized slides.
63:- 2023/10/10: The ASR-SpeakersDiarization combined pipeline [Paraformer-VAD-SPK](https://github.com/alibaba-damo-academy/FunASR/blob/main/egs_modelscope/asr_vad_spk/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn/demo.py) is now released. Experience the model to get recognition results with speaker information.
64:- 2023/10/07: [FunCodec](https://github.com/alibaba-damo-academy/FunCodec): A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec.
65:- 2023/09/01: The offline file transcription service 2.0 (CPU) of Mandarin has been released, with added support for ffmpeg, timestamp, and hotword models. For more details, please refer to ([docs](runtime#file-transcription-service-mandarin-cpu)).
66:- 2023/08/07: The real-time transcription service (CPU) of Mandarin has been released. For more details, please refer to ([docs](runtime#the-real-time-transcription-service-mandarin-cpu)).
67:- 2023/07/17: BAT is released, which is a low-latency and low-memory-consumption RNN-T model. For more details, please refer to ([BAT](egs/aishell/bat)).
68:- 2023/06/26: ASRU2023 Multi-Channel Multi-Party Meeting Transcription Challenge 2.0 completed the competition and announced the results. For more details, please refer to ([M2MeT2.0](https://alibaba-damo-academy.github.io/FunASR/m2met2/index.html)).
69:
70:</details>
71:
72:<a name="Installation"></a>
73:## Installation
74:
75:- Requirements
76:```text
77:python>=3.8
78:torch>=1.13
79:torchaudio
80:```
81:
82:- Install for pypi
83:```shell
84:pip3 install -U funasr
85:```
86:- Or install from source code
87:``` sh
88:git clone https://github.com/alibaba/FunASR.git && cd FunASR
89:pip3 install -e ./
90:```
91:- Install modelscope or huggingface_hub for the pretrained models (Optional)
92:
93:```shell
94:pip3 install -U modelscope huggingface_hub
95:```
96:
97:## Model Zoo
98:FunASR has open-sourced a large number of pre-trained models on industrial data. You are free to use, copy, modify, and share FunASR models under the [Model License Agreement](./MODEL_LICENSE). Below are some representative models, for more models please refer to the [Model Zoo](./model_zoo).
99:
100:(Note: ⭐ represents the ModelScope model zoo, 🤗 represents the Huggingface model zoo, 🍀 represents the OpenAI model zoo)
(291 more lines below)
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:23:14,344 - INFO - swea-agent - ========================= STEP 2 =========================
2025-05-12 13:23:14,355 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:23:29,144 - INFO - swea-lm - Response: ModelResponse(id='0217470273943889f4d0a2747848891c974a7a15d19ecdffc859e', created=1747027409, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `README.md` file provides a comprehensive overview of the FunASR toolkit, including installation instructions, model zoo, and quick start guides. Here's the plan based on the information:\n\n### Key Takeaways from README:\n1. **Installation**: FunASR can be installed via `pip` or from source. It requires Python >= 3.8 and PyTorch >= 1.13.\n2. **Model Zoo**: FunASR provides pre-trained models for speech recognition, which can be downloaded from ModelScope or HuggingFace.\n3. **Quick Start**: The toolkit supports easy inference with pre-trained models.\n\n### Next Steps:\n1. **Install FunASR**: Since the environment is already set up, we can proceed directly to using the toolkit.\n2. **Use Pre-trained Model**: We'll use a pre-trained model (e.g., Paraformer) for speech recognition.\n3. **Process Input Audio**: Run the inference on the provided audio file (`FunASR_01_input.wav`).\n4. **Save Output**: Save the recognized text to the specified output directory.\n\n### Next Action:\nLet's locate the script or example in the FunASR repository that demonstrates how to perform speech recognition on an audio file. We'll start by exploring the `examples` directory.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"path":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples"}', name='open'), id='call_ks428hmrjpyelx9jwv93z21g', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=302, prompt_tokens=15372, total_tokens=15674, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:23:29,154 - INFO - swea-agent - 💭 THOUGHT
The `README.md` file provides a comprehensive overview of the FunASR toolkit, including installation instructions, model zoo, and quick start guides. Here's the plan based on the information:

### Key Takeaways from README:
1. **Installation**: FunASR can be installed via `pip` or from source. It requires Python >= 3.8 and PyTorch >= 1.13.
2. **Model Zoo**: FunASR provides pre-trained models for speech recognition, which can be downloaded from ModelScope or HuggingFace.
3. **Quick Start**: The toolkit supports easy inference with pre-trained models.

### Next Steps:
1. **Install FunASR**: Since the environment is already set up, we can proceed directly to using the toolkit.
2. **Use Pre-trained Model**: We'll use a pre-trained model (e.g., Paraformer) for speech recognition.
3. **Process Input Audio**: Run the inference on the provided audio file (`FunASR_01_input.wav`).
4. **Save Output**: Save the recognized text to the specified output directory.

### Next Action:
Let's locate the script or example in the FunASR repository that demonstrates how to perform speech recognition on an audio file. We'll start by exploring the `examples` directory.

🎬 ACTION
open "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples"
2025-05-12 13:23:29,637 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
Error: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples is a directory. You can only open files. Use cd or ls to navigate directories.
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:23:29,643 - INFO - swea-agent - ========================= STEP 3 =========================
2025-05-12 13:23:29,654 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:23:34,551 - INFO - swea-lm - Response: ModelResponse(id='021747027409686971851c30c7472156997c7320c425be1b146a9', created=1747027414, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="To explore the `examples` directory, we'll first list its contents to find relevant scripts for speech recognition.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples"}', name='bash'), id='call_mybldmx292zrbapizgi2a26v', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=60, prompt_tokens=15830, total_tokens=15890, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:23:34,560 - INFO - swea-agent - 💭 THOUGHT
To explore the `examples` directory, we'll first list its contents to find relevant scripts for speech recognition.

🎬 ACTION
ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples
2025-05-12 13:23:34,822 - INFO - swea-agent - 🤖 MODEL INPUT
README.md     aishell	    deepspeed_conf		 wenetspeech
README_zh.md  common_voice  industrial_data_pretraining
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:23:34,827 - INFO - swea-agent - ========================= STEP 4 =========================
2025-05-12 13:23:34,838 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:23:40,775 - INFO - swea-lm - Response: ModelResponse(id='02174702741487021bfec8fef87687abbb7a7d8169c36f9ca32d9', created=1747027420, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `examples` directory contains several subdirectories, including `industrial_data_pretraining`, which might contain scripts for using pre-trained models. Let's explore this directory further to find a suitable script for speech recognition.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining"}', name='bash'), id='call_xri0bqqun6wg30lhudg44sli', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=88, prompt_tokens=15963, total_tokens=16051, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:23:40,784 - INFO - swea-agent - 💭 THOUGHT
The `examples` directory contains several subdirectories, including `industrial_data_pretraining`, which might contain scripts for using pre-trained models. Let's explore this directory further to find a suitable script for speech recognition.

🎬 ACTION
ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining
2025-05-12 13:23:41,047 - INFO - swea-agent - 🤖 MODEL INPUT
bicif_paraformer	  fsmn_kws	      paraformer-zh-spk     sense_voice
campplus_sv		  fsmn_kws_mt	      paraformer_streaming  transducer
conformer		  fsmn_vad_streaming  qwen_audio	    uniasr
contextual_paraformer	  lcbnet	      sanm_kws		    whisper
ct_transformer		  llm_asr	      sanm_kws_streaming
ct_transformer_streaming  monotonic_aligner   scama
ctc			  paraformer	      seaco_paraformer
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:23:41,054 - INFO - swea-agent - ========================= STEP 5 =========================
2025-05-12 13:23:41,065 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:23:47,873 - INFO - swea-lm - Response: ModelResponse(id='021747027421099b05d10b114a371c89846ad404d3650f23e9275', created=1747027427, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `industrial_data_pretraining` directory contains various subdirectories for different models and tasks. Since we need a general speech recognition script, the `paraformer` or `whisper` directories might be relevant. Let's check the `paraformer` directory first.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer"}', name='bash'), id='call_ltw7qkuglyl6a40e0alk79qp', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=103, prompt_tokens=16223, total_tokens=16326, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:23:47,882 - INFO - swea-agent - 💭 THOUGHT
The `industrial_data_pretraining` directory contains various subdirectories for different models and tasks. Since we need a general speech recognition script, the `paraformer` or `whisper` directories might be relevant. Let's check the `paraformer` directory first.

🎬 ACTION
ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer
2025-05-12 13:23:48,145 - INFO - swea-agent - 🤖 MODEL INPUT
README.md     demo.py	 export.sh    infer.sh
README_zh.md  export.py  finetune.sh  infer_from_local.sh
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:23:48,152 - INFO - swea-agent - ========================= STEP 6 =========================
2025-05-12 13:23:48,163 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:23:54,489 - INFO - swea-lm - Response: ModelResponse(id='021747027428197971851c30c7472156997c7320c425be1a3164b', created=1747027434, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `paraformer` directory contains a `demo.py` script, which is likely a demonstration script for using the Paraformer model for speech recognition. Let's open this script to see how it works.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"path":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py"}', name='open'), id='call_4y06uzzeaj5dzbxwv66w80ln', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=90, prompt_tokens=16399, total_tokens=16489, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:23:54,497 - INFO - swea-agent - 💭 THOUGHT
The `paraformer` directory contains a `demo.py` script, which is likely a demonstration script for using the Paraformer model for speech recognition. Let's open this script to see how it works.

🎬 ACTION
open "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py"
2025-05-12 13:23:54,984 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py (47 lines total)]
1:#!/usr/bin/env python3
2:# -*- encoding: utf-8 -*-
3:# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
4:#  MIT License  (https://opensource.org/licenses/MIT)
5:
6:from funasr import AutoModel
7:
8:model = AutoModel(
9:    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
10:    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
11:    vad_kwargs={"max_single_segment_time": 60000},
12:    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
13:    # spk_model="iic/speech_campplus_sv_zh-cn_16k-common",
14:)
15:
16:res = model.generate(
17:    input="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav",
18:    cache={},
19:)
20:
21:print(res)
22:
23:
24:""" call english model like below for detailed timestamps
25:# choose english paraformer model first
26:# iic/speech_paraformer_asr-en-16k-vocab4199-pytorch
27:res = model.generate(
28:    input="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_en.wav",
29:    cache={},
30:    pred_timestamp=True,
31:    return_raw_text=True,
32:    sentence_timestamp=True,
33:    en_post_proc=True,
34:)
35:"""
36:
37:""" can not use currently
38:from funasr import AutoFrontend
39:
40:frontend = AutoFrontend(model="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch")
41:
42:fbanks = frontend(input="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav", batch_size=2)
43:
44:for batch_idx, fbank_dict in enumerate(fbanks):
45:    res = model.generate(**fbank_dict)
46:    print(res)
47:"""
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:23:54,994 - INFO - swea-agent - ========================= STEP 7 =========================
2025-05-12 13:23:55,004 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:24:08,397 - INFO - swea-lm - Response: ModelResponse(id='0217470274350338c7ec58663f8b52b23d9bafd9ef699dce5a2b2', created=1747027448, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='The `demo.py` script demonstrates how to use the `AutoModel` class from FunASR to perform speech recognition on an audio file. Here\'s how it works:\n\n1. **Model Initialization**: The script initializes a `Paraformer` model with additional components like VAD (Voice Activity Detection) and punctuation restoration.\n2. **Audio Input**: The script processes an audio file from a URL (`input="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav"`).\n3. **Output**: The recognized text is printed to the console.\n\n### Next Steps:\n1. **Modify the Script**: We\'ll adapt this script to process our local audio file (`FunASR_01_input.wav`) instead of the URL.\n2. **Save Output**: Instead of printing the result, we\'ll save it to the specified output directory.\n\n### Next Action:\nLet\'s create a modified version of this script to process our input file and save the output. We\'ll use the same `AutoModel` setup but replace the input and output handling.', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"filename":"recognize_speech.py"}', name='create'), id='call_hp86zei5d8lhlj66r1bvr6yl', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=260, prompt_tokens=13790, total_tokens=14050, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:24:08,408 - INFO - swea-agent - 💭 THOUGHT
The `demo.py` script demonstrates how to use the `AutoModel` class from FunASR to perform speech recognition on an audio file. Here's how it works:

1. **Model Initialization**: The script initializes a `Paraformer` model with additional components like VAD (Voice Activity Detection) and punctuation restoration.
2. **Audio Input**: The script processes an audio file from a URL (`input="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav"`).
3. **Output**: The recognized text is printed to the console.

### Next Steps:
1. **Modify the Script**: We'll adapt this script to process our local audio file (`FunASR_01_input.wav`) instead of the URL.
2. **Save Output**: Instead of printing the result, we'll save it to the specified output directory.

### Next Action:
Let's create a modified version of this script to process our input file and save the output. We'll use the same `AutoModel` setup but replace the input and output handling.

🎬 ACTION
create recognize_speech.py
2025-05-12 13:24:08,897 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: recognize_speech.py (1 lines total)]
1:
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:24:08,905 - INFO - swea-agent - ========================= STEP 8 =========================
2025-05-12 13:24:08,916 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:24:28,462 - INFO - swea-lm - Response: ModelResponse(id='02174702744894599294c8023550a5391a33bac7bbd19e1a3d397', created=1747027468, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="Now, let's insert the modified script into `recognize_speech.py`. We'll use the same model setup but process our local audio file and save the output to the specified directory.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"text":"#!/usr/bin/env python3\\n# -*- encoding: utf-8 -*-\\n# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.\\n#  MIT License  (https://opensource.org/licenses/MIT)\\n\\nfrom funasr import AutoModel\\n\\n# Initialize the model\\nmodel = AutoModel(\\n    model=\\"iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\\",\\n    vad_model=\\"iic/speech_fsmn_vad_zh-cn-16k-common-pytorch\\",\\n    vad_kwargs={\\"max_single_segment_time\\": 60000},\\n    punc_model=\\"iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch\\",\\n)\\n\\n# Process the input audio file\\ninput_file = \\"/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav\\"\\nres = model.generate(\\n    input=input_file,\\n    cache={},\\n)\\n\\n# Save the output to the specified directory\\noutput_dir = \\"/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01\\"\\noutput_file = f\\"{output_dir}/output.txt\\"\\n\\nimport os\\nos.makedirs(output_dir, exist_ok=True)\\n\\nwith open(output_file, \\"w\\", encoding=\\"utf-8\\") as f:\\n    f.write(res)\\n\\nprint(f\\"Speech recognition completed. Output saved to {output_file}\\")"}', name='insert'), id='call_ztmgw7d2xp6k9ukumop6igcf', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=431, prompt_tokens=14028, total_tokens=14459, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:24:28,472 - INFO - swea-agent - 💭 THOUGHT
Now, let's insert the modified script into `recognize_speech.py`. We'll use the same model setup but process our local audio file and save the output to the specified directory.

🎬 ACTION
insert '#!/usr/bin/env python3
# -*- encoding: utf-8 -*-
# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
#  MIT License  (https://opensource.org/licenses/MIT)

from funasr import AutoModel

# Initialize the model
model = AutoModel(
    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
    vad_kwargs={"max_single_segment_time": 60000},
    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
)

# Process the input audio file
input_file = "/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
res = model.generate(
    input=input_file,
    cache={},
)

# Save the output to the specified directory
output_dir = "/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
output_file = f"{output_dir}/output.txt"

import os
os.makedirs(output_dir, exist_ok=True)

with open(output_file, "w", encoding="utf-8") as f:
    f.write(res)

print(f"Speech recognition completed. Output saved to {output_file}")'
2025-05-12 13:24:29,378 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /GitTaskBench/recognize_speech.py (34 lines total)]
1:
2:#!/usr/bin/env python3
3:# -*- encoding: utf-8 -*-
4:# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
5:#  MIT License  (https://opensource.org/licenses/MIT)
6:
7:from funasr import AutoModel
8:
9:# Initialize the model
10:model = AutoModel(
11:    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
12:    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
13:    vad_kwargs={"max_single_segment_time": 60000},
14:    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
15:)
16:
17:# Process the input audio file
18:input_file = "/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
19:res = model.generate(
20:    input=input_file,
21:    cache={},
22:)
23:
24:# Save the output to the specified directory
25:output_dir = "/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
26:output_file = f"{output_dir}/output.txt"
27:
28:import os
29:os.makedirs(output_dir, exist_ok=True)
30:
31:with open(output_file, "w", encoding="utf-8") as f:
32:    f.write(res)
33:
34:print(f"Speech recognition completed. Output saved to {output_file}")
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:24:29,389 - INFO - swea-agent - ========================= STEP 9 =========================
2025-05-12 13:24:29,399 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:24:37,763 - INFO - swea-lm - Response: ModelResponse(id='021747027469428012d362c6c478fde46ec9847587ba156a55bea', created=1747027477, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The script `recognize_speech.py` has been successfully created. It initializes the FunASR model, processes the input audio file (`FunASR_01_input.wav`), and saves the recognized text to the specified output directory (`/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01/output.txt`).\n\n### Next Steps:\n1. **Run the Script**: Execute the script to perform speech recognition on the input audio file.\n2. **Verify Output**: Ensure the output is saved correctly and contains the expected text.\n\n### Next Action:\nLet's run the script to process the audio file.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"python recognize_speech.py"}', name='bash'), id='call_e91pyf59rre95rof68gb2za8', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=156, prompt_tokens=14979, total_tokens=15135, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:24:37,772 - INFO - swea-agent - 💭 THOUGHT
The script `recognize_speech.py` has been successfully created. It initializes the FunASR model, processes the input audio file (`FunASR_01_input.wav`), and saves the recognized text to the specified output directory (`/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01/output.txt`).

### Next Steps:
1. **Run the Script**: Execute the script to perform speech recognition on the input audio file.
2. **Verify Output**: Ensure the output is saved correctly and contains the expected text.

### Next Action:
Let's run the script to process the audio file.

🎬 ACTION
python recognize_speech.py
2025-05-12 13:24:38,070 - INFO - swea-agent - 🤖 MODEL INPUT
Traceback (most recent call last):
  File "/GitTaskBench/recognize_speech.py", line 7, in <module>
    from funasr import AutoModel
ModuleNotFoundError: No module named 'funasr'
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:24:38,079 - INFO - swea-agent - ========================= STEP 10 =========================
2025-05-12 13:24:38,090 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:24:47,126 - INFO - swea-lm - Response: ModelResponse(id='021747027478122e6c23bc29f4c4d640c5954d636de39ffcb4803', created=1747027487, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The error indicates that the `funasr` module is not installed in the current environment. Since we cannot install packages directly, we need to ensure the FunASR repository is accessible by adding its path to `PYTHONPATH`.\n\n### Next Steps:\n1. **Add FunASR to PYTHONPATH**: Update the environment to include the FunASR repository path.\n2. **Re-run the Script**: Execute the script again after updating the environment.\n\n### Next Action:\nLet's update the `PYTHONPATH` to include the FunASR repository and then re-run the script.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"export PYTHONPATH=\\"$PYTHONPATH:/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR\\" && python recognize_speech.py"}', name='bash'), id='call_w7qbhz59c1a69vs2tel41215', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=175, prompt_tokens=15059, total_tokens=15234, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:24:47,135 - INFO - swea-agent - 💭 THOUGHT
The error indicates that the `funasr` module is not installed in the current environment. Since we cannot install packages directly, we need to ensure the FunASR repository is accessible by adding its path to `PYTHONPATH`.

### Next Steps:
1. **Add FunASR to PYTHONPATH**: Update the environment to include the FunASR repository path.
2. **Re-run the Script**: Execute the script again after updating the environment.

### Next Action:
Let's update the `PYTHONPATH` to include the FunASR repository and then re-run the script.

🎬 ACTION
export PYTHONPATH="$PYTHONPATH:/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR" && python recognize_speech.py
2025-05-12 13:24:48,464 - INFO - swea-agent - 🤖 MODEL INPUT
Traceback (most recent call last):
  File "/GitTaskBench/recognize_speech.py", line 7, in <module>
    from funasr import AutoModel
  File "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/__init__.py", line 39, in <module>
    from funasr.auto.auto_model import AutoModel
  File "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/auto_model.py", line 9, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:24:48,475 - INFO - swea-agent - ========================= STEP 11 =========================
2025-05-12 13:24:48,485 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:24:58,402 - INFO - swea-lm - Response: ModelResponse(id='0217470274885219f4d0a2747848891c974a7a15d19ecdf67c034', created=1747027498, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The error now indicates that the `torch` module (PyTorch) is not installed. Since we cannot install packages in this environment, we need to find an alternative approach to complete the task.\n\n### Next Steps:\n1. **Check for Pre-installed Tools**: Look for pre-installed tools or scripts in the FunASR repository that might not require `torch` or can run in a minimal environment.\n2. **Use Command-Line Tools**: If FunASR provides command-line tools, we can use them directly.\n\n### Next Action:\nLet's explore the FunASR repository for any command-line tools or scripts that might not require `torch`.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/bin"}', name='bash'), id='call_joqixkdm68rnejmv1kkaon05', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=173, prompt_tokens=15362, total_tokens=15535, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:24:58,410 - INFO - swea-agent - 💭 THOUGHT
The error now indicates that the `torch` module (PyTorch) is not installed. Since we cannot install packages in this environment, we need to find an alternative approach to complete the task.

### Next Steps:
1. **Check for Pre-installed Tools**: Look for pre-installed tools or scripts in the FunASR repository that might not require `torch` or can run in a minimal environment.
2. **Use Command-Line Tools**: If FunASR provides command-line tools, we can use them directly.

### Next Action:
Let's explore the FunASR repository for any command-line tools or scripts that might not require `torch`.

🎬 ACTION
ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/bin
2025-05-12 13:24:58,679 - INFO - swea-agent - 🤖 MODEL INPUT
ls: cannot access '/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/bin': No such file or directory
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:24:58,691 - INFO - swea-agent - ========================= STEP 12 =========================
2025-05-12 13:24:58,702 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:25:03,621 - INFO - swea-lm - Response: ModelResponse(id='0217470274987328c7ec58663f8b52b23d9bafd9ef699dc963285', created=1747027503, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `bin` directory does not exist, so we'll look for any executable scripts or tools in the repository root or other directories.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR"}', name='bash'), id='call_e0y9zgfm96jbd4zzmub8xozx', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=63, prompt_tokens=14769, total_tokens=14832, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:25:03,629 - INFO - swea-agent - 💭 THOUGHT
The `bin` directory does not exist, so we'll look for any executable scripts or tools in the repository root or other directories.

🎬 ACTION
ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
2025-05-12 13:25:03,895 - INFO - swea-agent - 🤖 MODEL INPUT
Acknowledge.md	 MinMo_gitlab  docs		    funasr     tests
Contribution.md  README.md     examples		    model_zoo  web-pages
LICENSE		 benchmarks    export.py	    runtime
MODEL_LICENSE	 data	       fun_text_processing  setup.py
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:25:03,909 - INFO - swea-agent - ========================= STEP 13 =========================
2025-05-12 13:25:03,919 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:25:10,637 - INFO - swea-lm - Response: ModelResponse(id='0217470275039508c7ec58663f8b52b23d9bafd9ef699dcbe3078', created=1747027510, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The repository contains several directories and files, including `funasr` (the main package), `examples`, and `runtime`. The `runtime` directory might contain pre-built tools or scripts that can be used without installing additional dependencies.\n\n### Next Action:\nLet's explore the `runtime` directory to see if it contains any executable tools for speech recognition.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime"}', name='bash'), id='call_hniq3gk8edtlgwnughzomts6', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=109, prompt_tokens=14823, total_tokens=14932, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:25:10,646 - INFO - swea-agent - 💭 THOUGHT
The repository contains several directories and files, including `funasr` (the main package), `examples`, and `runtime`. The `runtime` directory might contain pre-built tools or scripts that can be used without installing additional dependencies.

### Next Action:
Let's explore the `runtime` directory to see if it contains any executable tools for speech recognition.

🎬 ACTION
ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime
2025-05-12 13:25:10,910 - INFO - swea-agent - 🤖 MODEL INPUT
__init__.py   funasr_api  ios		  quick_start_zh.md    ssl_key
android       golang	  java		  readme.md	       tools
csharp	      grpc	  onnxruntime	  readme_cn.md	       triton_gpu
deploy_tools  html5	  python	  run_server.sh        websocket
docs	      http	  quick_start.md  run_server_2pass.sh
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:25:10,925 - INFO - swea-agent - ========================= STEP 14 =========================
2025-05-12 13:25:10,935 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:25:16,708 - INFO - swea-lm - Response: ModelResponse(id='021747027510970c4a2b61157cbd92ca72b360ef1ce198a27cf64', created=1747027516, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `runtime` directory contains various tools and scripts, including `python`, `onnxruntime`, and `tools`. Let's explore the `tools` directory to see if it contains any pre-built tools for speech recognition.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools"}', name='bash'), id='call_m5vlnmepf1kiplgnksf2vj0f', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=85, prompt_tokens=14492, total_tokens=14577, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:25:16,717 - INFO - swea-agent - 💭 THOUGHT
The `runtime` directory contains various tools and scripts, including `python`, `onnxruntime`, and `tools`. Let's explore the `tools` directory to see if it contains any pre-built tools for speech recognition.

🎬 ACTION
ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools
2025-05-12 13:25:16,982 - INFO - swea-agent - 🤖 MODEL INPUT
fst  path.sh  train_compile_ngram.sh  utils
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:25:16,997 - INFO - swea-agent - ========================= STEP 15 =========================
2025-05-12 13:25:17,007 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:25:22,488 - INFO - swea-lm - Response: ModelResponse(id='021747027517043315f63336899cca155604ab2de3192feecb0bf', created=1747027522, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `tools` directory does not contain any executable tools for speech recognition. Let's check the `python` directory in `runtime` for any relevant scripts.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/python"}', name='bash'), id='call_zmveb2ystkrcnhgsjoe9ctc5', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=71, prompt_tokens=14553, total_tokens=14624, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:25:22,496 - INFO - swea-agent - 💭 THOUGHT
The `tools` directory does not contain any executable tools for speech recognition. Let's check the `python` directory in `runtime` for any relevant scripts.

🎬 ACTION
ls /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/python
2025-05-12 13:25:22,760 - INFO - swea-agent - 🤖 MODEL INPUT
__init__.py  grpc  http  libtorch  onnxruntime	utils  websocket
(Open file: /GitTaskBench/recognize_speech.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:25:22,776 - INFO - swea-agent - ========================= STEP 16 =========================
2025-05-12 13:25:22,787 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:25:30,555 - INFO - swea-lm - Response: ModelResponse(id='021747027522823c4a2b61157cbd92ca72b360ef1ce198a93ad22', created=1747027530, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `python` directory contains subdirectories like `libtorch` and `onnxruntime`, which might be used for running models without full PyTorch installation. However, since we cannot install or configure these tools, we need to find another approach.\n\n### Alternative Approach:\nGiven the constraints, we'll use the `export.py` script in the repository root to check if it provides a way to export models or run inference without full PyTorch installation.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"path":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/export.py"}', name='open'), id='call_uhtk44kjh61riwuadkye87sr', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=132, prompt_tokens=14509, total_tokens=14641, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:25:30,565 - INFO - swea-agent - 💭 THOUGHT
The `python` directory contains subdirectories like `libtorch` and `onnxruntime`, which might be used for running models without full PyTorch installation. However, since we cannot install or configure these tools, we need to find another approach.

### Alternative Approach:
Given the constraints, we'll use the `export.py` script in the repository root to check if it provides a way to export models or run inference without full PyTorch installation.

🎬 ACTION
open "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/export.py"
2025-05-12 13:25:31,089 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/export.py (10 lines total)]
1:# method2, inference from local path
2:from funasr import AutoModel
3:
4:model = AutoModel(
5:    model="iic/emotion2vec_base",
6:    hub="ms"
7:)
8:
9:res = model.export(type="onnx", quantize=False, opset_version=13, device='cpu')  # fp32 onnx-gpu
10:# res = model.export(type="onnx_fp16", quantize=False, opset_version=13, device='cuda')  # fp16 onnx-gpu
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/export.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:25:31,107 - INFO - swea-agent - ========================= STEP 17 =========================
2025-05-12 13:25:31,118 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 13:25:40,800 - INFO - swea-lm - Response: ModelResponse(id='0217470275311519f4d0a2747848891c974a7a15d19ecdfabbadb', created=1747027540, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `export.py` script demonstrates how to export a model to ONNX format, which might allow us to run inference without PyTorch. However, this still requires the `funasr` module, which depends on `torch`.\n\n### Conclusion:\nGiven the constraints (no ability to install packages or configure dependencies), we cannot proceed with running the FunASR toolkit directly. \n\n### Final Steps:\n1. **Report the Issue**: Since the environment lacks the necessary dependencies (`torch` and `funasr`), we cannot complete the task as intended.\n2. **Alternative Suggestion**: If possible, provide a pre-configured environment with the required dependencies or use a different tool that does not require `torch`.\n\n### Next Action:\nLet's summarize the findings and conclude the task.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='submit'), id='call_e9m19he4ig54j2n3aerjmecl', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=175, prompt_tokens=14880, total_tokens=15055, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 13:25:40,809 - INFO - swea-agent - 💭 THOUGHT
The `export.py` script demonstrates how to export a model to ONNX format, which might allow us to run inference without PyTorch. However, this still requires the `funasr` module, which depends on `torch`.

### Conclusion:
Given the constraints (no ability to install packages or configure dependencies), we cannot proceed with running the FunASR toolkit directly. 

### Final Steps:
1. **Report the Issue**: Since the environment lacks the necessary dependencies (`torch` and `funasr`), we cannot complete the task as intended.
2. **Alternative Suggestion**: If possible, provide a pre-configured environment with the required dependencies or use a different tool that does not require `torch`.

### Next Action:
Let's summarize the findings and conclude the task.

🎬 ACTION
submit
2025-05-12 13:25:41,304 - INFO - swea-agent - Found submission: diff --git a/recognize_speech.py b/recognize_speech.py
new file mode 100644
index 00000000..63640861
--- /dev/null
+++ b/recognize_speech.py
@@ -0,0 +1,34 @@
+
+#!/usr/bin/env python3
+# -*- encoding: utf-8 -*-
+# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
+#  MIT License  (https://opensource.org/licenses/MIT)
+
+from funasr import AutoModel
+
+# Initialize the model
+model = AutoModel(
+    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
+    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
+    vad_kwargs={"max_single_segment_time": 60000},
+    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
+)
+
+# Process the input audio file
+input_file = "/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
+res = model.generate(
+    input=input_file,
+    cache={},
+)
+
+# Save the output to the specified directory
+output_dir = "/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
+output_file = f"{output_dir}/output.txt"
+
+import os
+os.makedirs(output_dir, exist_ok=True)
+
+with open(output_file, "w", encoding="utf-8") as f:
+    f.write(res)
+
+print(f"Speech recognition completed. Output saved to {output_file}")
\ No newline at end of file

2025-05-12 13:25:41,310 - INFO - swea-agent - 🤖 MODEL INPUT
diff --git a/recognize_speech.py b/recognize_speech.py
new file mode 100644
index 00000000..63640861
--- /dev/null
+++ b/recognize_speech.py
@@ -0,0 +1,34 @@
+
+#!/usr/bin/env python3
+# -*- encoding: utf-8 -*-
+# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
+#  MIT License  (https://opensource.org/licenses/MIT)
+
+from funasr import AutoModel
+
+# Initialize the model
+model = AutoModel(
+    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
+    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
+    vad_kwargs={"max_single_segment_time": 60000},
+    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
+)
+
+# Process the input audio file
+input_file = "/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
+res = model.generate(
+    input=input_file,
+    cache={},
+)
+
+# Save the output to the specified directory
+output_dir = "/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
+output_file = f"{output_dir}/output.txt"
+
+import os
+os.makedirs(output_dir, exist_ok=True)
+
+with open(output_file, "w", encoding="utf-8") as f:
+    f.write(res)
+
+print(f"Speech recognition completed. Output saved to {output_file}")
\ No newline at end of file

(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/export.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 13:25:41,330 - INFO - swea-agent - Trajectory saved to /data/code/agent_new/SWE-agent/trajectories/i-youwang/default__openai/deepseek-v3__t-0.00__p-1.00__c-0.00___2dc60e/2dc60e/2dc60e.traj
2025-05-12 13:25:41,344 - INFO - swea-run - Done
2025-05-12 13:25:41,345 - INFO - swea-env - Beginning environment shutdown...
2025-05-12 15:42:23,679 - INFO - swea-run - Starting environment
2025-05-12 15:42:23,741 - INFO - rex-deploy - Starting container 3eb72bc4a848-36aae9ff-4b52-47cb-b918-fb065ee59e9e with image 3eb72bc4a848 serving on port 38025
2025-05-12 15:42:23,752 - INFO - rex-deploy - Starting runtime at 38025
2025-05-12 15:42:25,031 - INFO - rex-deploy - Runtime started in 1.28s
2025-05-12 15:42:25,807 - INFO - swea-env - Environment Initialized
2025-05-12 15:44:33,068 - INFO - swea-run - Running agent
2025-05-12 15:44:33,080 - INFO - swea-agent - Setting up agent for instance 2dc60e
2025-05-12 15:44:33,081 - INFO - swea-agent - Trajectory will be saved to /data/code/agent_new/SWE-agent/trajectories/i-youwang/default__openai/deepseek-v3__t-0.00__p-1.00__c-0.00___2dc60e/2dc60e/2dc60e.traj
2025-05-12 15:44:40,330 - INFO - swea-tools - Resetting tools
2025-05-12 15:44:40,794 - INFO - swea-agent - SYSTEM (main)
SETTING: You are an autonomous programmer, and you're working directly in the command line with a special interface.

The special interface consists of a file editor that shows you 100 lines of a file at a time.
In addition to typical bash commands, you can also use specific commands to help you navigate and edit files.
To call a command, you need to invoke it with a function call/tool call.

Please note that THE EDIT COMMAND REQUIRES PROPER INDENTATION.

For example, if you are looking at this file:

def fct():
    print("Hello world")

and you want to edit the file to read:

def fct():
    print("Hello")
    print("world")

you search string should be `Hello world` and your replace string should be `"Hello"\n    print("world")`
(note the extra spaces before the print statement!).

You could also get the same result by search for `    print("Hello world")` and replace with `    print("Hello")\n    print("world")`.

RESPONSE FORMAT:
Your shell prompt is formatted as follows:
(Open file: <path>)
(Current directory: <cwd>)
bash-$

First, you should _always_ include a general thought about what you're going to do next.
Then, for every response, you must include exactly _ONE_ tool call/function call.

Remember, you should always include a _SINGLE_ tool call/function call and then wait for a response from the shell before continuing with more discussion and commands. Everything you include in the DISCUSSION section will be saved for future reference.
If you'd like to issue two commands at once, PLEASE DO NOT DO THAT! Please instead first submit just the first tool call, and then after receiving a response you'll be able to issue the second .
Note that the environment does NOT support interactive session commands (e.g. python, vim), so please do not invoke them.
2025-05-12 15:44:40,800 - INFO - swea-agent - DEMONSTRATION: /data/code/agent_new/SWE-agent/trajectories/demonstrations/replay__marshmallow-code__marshmallow-1867__function_calling_replace__install-1/marshmallow-code__marshmallow-1867.traj
2025-05-12 15:44:40,955 - INFO - swea-agent - 🤖 MODEL INPUT
We're currently solving the following issue within our repository. Here's the issue text:
ISSUE:

## 任务描述
从给定的仓库列表中选取合适的仓库，实现语音识别功能，输出音频的文字内容

## 可用仓库
仓库名称: FunASR
仓库路径 (绝对): /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
理解指南: ['阅读README.md了解项目基本功能和使用方法']

## 文件路径
输入：
文件路径 (绝对): /data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav
文件描述: 需要识别的语音文件

输出：
输出文件目录:/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01, 如果只有一个文件，就以 `output` 命名; 如果存在多个以 `output_01`开始命名，格式根据需求指定。

## 补充说明
**核心目标**: 快速理解和分析代码仓库，生成并执行必要的代码或调用工具，以高效、准确地完成用户指定的任务。

## 工作流程与规范

1.  **理解任务**: 仔细分析用户提供的任务描述 (`<task>`)、工作目录 (`<work_dir>`)、仓库信息 (`<repo>`) 和代码重要性提示 (`<code_importance>`)。
2.  **规划方案**: 
    *   如果没有现成计划，先制定清晰的执行步骤。请先阅读代码库的README.md文件，了解代码库的结构和使用方法。
    *   如果没有README.md文件或者README.md文件中没有提供足够信息，请先阅读代码库的代码，了解代码库的结构和使用方法。
    *   明确哪些步骤需要编写代码，哪些步骤依赖语言理解和工具调用。
    *   代码生成和执行过程中，涉及到路径的请使用绝对路径，不要使用相对路径，以免出现路径错误。
3.  **代码库分析**: 
    *   **探索结构**: 快速了解仓库的整体文件和目录结构, 请使用绝对路径。
    *   **识别关键文件**: 优先关注 `README.md`, 配置文件, 主入口脚本等。
    *   **依赖管理**: 
        *   检查 `requirements.txt` 或类似文件，确定所需依赖。
        *   **如果需要安装依赖**：在代码块中包含安装命令 (e.g., `pip install -r requirements.txt` 或 `pip install specific_package`)。检查包是否存在避免重复安装。
        *   **不要使用conda install，请使用pip install**。
        *   **环境配置**: Python/Conda环境已预设，无需额外配置。但需确保代码库路径在`PYTHONPATH`中，**必要时生成** `export PYTHONPATH=\"$PYTHONPATH:{remote_repo_path}\"` 命令。
4. 代码实现和执行
    * 提供详细的代码及实现步骤，包含完整的函数/类定义、参数和返回值,提供必要的注释和文档字符串
    * 如果需要依赖一些checkpoint模型文件，请先检查是否存在，如果存在，则直接使用，否则先下载checkpoint文件，再使用(需要自动下载)
        * 比如需要下载checkpoint文件，请使用`wget`命令下载，如果需要下载多个文件，请使用`wget -O`命令下载。

5.  **错误处理与迭代**: 
    *   检查代码执行结果。
    *   如果出现错误，分析原因，**修复代码**并重新生成**完整**脚本进行尝试。
    *   如果多次尝试后仍无法解决或任务无法完成，分析原因并考虑替代方案。
6.  **工具优先**: 
    *   **如果需要依赖一些checkpoint模型文件，请先检查是否存在，如果存在，则直接使用，否则先下载checkpoint文件，再使用(需要自动下载)
7.  **任务完成**: 
    *   当任务成功完成，或确认无法完成时，提供清晰的总结。

## !! 关键约束与强制要求 !!

*   **绝对路径**: 在代码中处理文件（特别是数据加载）时，**必须**使用**绝对路径**。
*   **提供的仓库 > 代码**: 现有仓库代码能完成的任务，**严禁**自行重新编写代码实现。
*   **请先阅读代码库的README.md文件，了解代码库的结构和使用方法**。如果没有README.md文件或者README.md文件中没有提供足够信息，请先阅读代码库的代码，了解代码库的结构和使用方法。

** 执行前首先运行 `eval $(curl -s http://deploy.i.shaipower.com/httpproxy)`

INSTRUCTIONS:
Now, you're going to solve this issue on your own. Your terminal session has started and you're in the repository's root directory. You can use any bash commands or the special interface to help you. Edit all the files you need to and run any checks or tests that you want.
Remember, YOU SHOULD ALWAYS INCLUDE EXACTLY ONE TOOL CALL/FUNCTION CALL PER RESPONSE.
When you're satisfied with all of the changes you've made, you can submit your changes to the code base by simply running the submit command.
Note however that you cannot use any interactive session commands (e.g. python, vim) in this environment, but you can write scripts and run them. E.g. you can write a python script and then run it with the python command.

NOTE ABOUT THE EDIT COMMAND: Indentation really matters! When editing a file, make sure to insert appropriate indentation before each line!

GENERAL IMPORTANT TIPS:

1. If you run a command and it doesn't work, try running a different command. A command that did not work once will not work the second time unless you modify it!

2. If you open a file and need to get to an area around a specific line that is not in the first 100 lines, say line 583, don't just use the scroll_down command multiple times. Instead, use the goto 583 command. It's much quicker.

3. If the bug reproduction script requires inputting/reading a specific file, such as buggy-input.png, and you'd like to understand how to input that file, conduct a search in the existing repo code, to see whether someone else has already done that. Do this by running the command: find_file "buggy-input.png" If that doesn't work, use the linux 'find' command.

4. Always make sure to look at the currently open file and the current working directory (which appears right after the currently open file). The currently open file might be in a different directory than the working directory! Note that some commands, such as 'create', open files, so they might change the current open file.

5. When editing files, it is easy to accidentally to write code with incorrect indentation or make other mistakes. Always check the code after you issue an edit to make sure that it reflects what you wanted to accomplish. If it didn't, issue another command to fix it.

6. When editing files, first explain the code you want to edit and why it is causing the problem. Then explain the edit you want to make and how it fixes the problem. Explain how the edit does not break existing functionality.

7. Do not try to install any packages with `pip`, `conda`, or any other way. This will usually not work. If the environment is not set up correctly, try to fix the issue without executing python code or running any tests that require the package installed.

STRATEGY:

1. Always start by trying to replicate the bug that the issues discusses.
  If the issue includes code for reproducing the bug, we recommend that you re-implement that in your environment, and run it to make sure you can reproduce the bug.
  Then start trying to fix it.

  If the bug reproduction script does not print anything when it successfully runs, we recommend adding a print("Script completed successfully, no errors.") command at the end of the file,
  so that you can be sure that the script indeed ran fine all the way through.

2. Locate relevant code using the find and search commands. `open` the file you want to edit.

3. Use the `edit` command to perform edits.

4. When you think you've fixed the bug, re-run the bug reproduction script to make sure that the bug has indeed been fixed.

5. Create additional tests to verify the fix in a style similar to the existing reproduction script. In particular, make sure to test edge cases.
   If you find any issues, go back to the file you edited and perform further edits.

(Open file: n/a)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:44:40,964 - INFO - swea-agent - ========================= STEP 1 =========================
2025-05-12 15:44:40,973 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:44:51,916 - INFO - swea-lm - Response: ModelResponse(id='021747035881063877b79ccd965086b7c0f04f8d6f379a1344940', created=1747035891, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="To solve this task, we need to use the FunASR repository to perform speech recognition on the provided audio file (`FunASR_01_input.wav`). The output should be saved in the specified output directory. \n\n### Step 1: Understand the FunASR Repository\nFirst, we need to explore the FunASR repository to understand its structure and usage. The repository is located at `/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR`. We should start by reading the `README.md` file to understand how to use the repository for speech recognition.\n\n### Step 2: Locate the README.md File\nLet's find and open the `README.md` file in the FunASR repository.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"path":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md"}', name='open'), id='call_47e9nx3brmfdng82fdwplwgw', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=192, prompt_tokens=11595, total_tokens=11787, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:44:51,924 - INFO - swea-agent - 💭 THOUGHT
To solve this task, we need to use the FunASR repository to perform speech recognition on the provided audio file (`FunASR_01_input.wav`). The output should be saved in the specified output directory. 

### Step 1: Understand the FunASR Repository
First, we need to explore the FunASR repository to understand its structure and usage. The repository is located at `/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR`. We should start by reading the `README.md` file to understand how to use the repository for speech recognition.

### Step 2: Locate the README.md File
Let's find and open the `README.md` file in the FunASR repository.

🎬 ACTION
open "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md"
2025-05-12 15:44:52,419 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md (391 lines total)]
1:[//]: # (<div align="left"><img src="docs/images/funasr_logo.jpg" width="400"/></div>)
2:
3:([简体中文](./README_zh.md)|English)
4:
5:[//]: # (# FunASR: A Fundamental End-to-End Speech Recognition Toolkit)
6:
7:[![SVG Banners](https://svg-banners.vercel.app/api?type=origin&text1=FunASR🤠&text2=💖%20A%20Fundamental%20End-to-End%20Speech%20Recognition%20Toolkit&width=800&height=210)](https://github.com/Akshay090/svg-banners)
8:
9:[![PyPI](https://img.shields.io/pypi/v/funasr)](https://pypi.org/project/funasr/)
10:
11:<p align="center">
12:<a href="https://trendshift.io/repositories/3839" target="_blank"><img src="https://trendshift.io/api/badge/repositories/3839" alt="alibaba-damo-academy%2FFunASR | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>
13:</p>
14:
15:<strong>FunASR</strong> hopes to build a bridge between academic research and industrial applications on speech recognition. By supporting the training & finetuning of the industrial-grade speech recognition model, researchers and developers can conduct research and production of speech recognition models more conveniently, and promote the development of speech recognition ecology. ASR for Fun！
16:
17:[**Highlights**](#highlights)
18:| [**News**](https://github.com/alibaba-damo-academy/FunASR#whats-new) 
19:| [**Installation**](#installation)
20:| [**Quick Start**](#quick-start)
21:| [**Tutorial**](https://github.com/alibaba-damo-academy/FunASR/blob/main/docs/tutorial/README.md)
22:| [**Runtime**](./runtime/readme.md)
23:| [**Model Zoo**](#model-zoo)
24:| [**Contact**](#contact)
25:
26:
27:
28:
29:<a name="highlights"></a>
30:## Highlights
31:- FunASR is a fundamental speech recognition toolkit that offers a variety of features, including speech recognition (ASR), Voice Activity Detection (VAD), Punctuation Restoration, Language Models, Speaker Verification, Speaker Diarization and multi-talker ASR. FunASR provides convenient scripts and tutorials, supporting inference and fine-tuning of pre-trained models.
32:- We have released a vast collection of academic and industrial pretrained models on the [ModelScope](https://www.modelscope.cn/models?page=1&tasks=auto-speech-recognition) and [huggingface](https://huggingface.co/FunASR), which can be accessed through our [Model Zoo](https://github.com/alibaba-damo-academy/FunASR/blob/main/docs/model_zoo/modelscope_models.md). The representative [Paraformer-large](https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary), a non-autoregressive end-to-end speech recognition model, has the advantages of high accuracy, high efficiency, and convenient deployment, supporting the rapid construction of speech recognition services. For more details on service deployment, please refer to the [service deployment document](runtime/readme_cn.md). 
33:
34:
35:<a name="whats-new"></a>
36:## What's new:
37:- 2024/10/29: Real-time Transcription Service 1.12 released, The 2pass-offline mode supports the SensevoiceSmal model；([docs](runtime/readme.md));
38:- 2024/10/10：Added support for the Whisper-large-v3-turbo model, a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. It can be downloaded from the [modelscope](examples/industrial_data_pretraining/whisper/demo.py), and [openai](examples/industrial_data_pretraining/whisper/demo_from_openai.py).
39:- 2024/09/26: Offline File Transcription Service 4.6, Offline File Transcription Service of English 1.7, Real-time Transcription Service 1.11 released, fix memory leak & Support the SensevoiceSmall onnx model；File Transcription Service 2.0 GPU released, Fix GPU memory leak; ([docs](runtime/readme.md));
40:- 2024/09/25：keyword spotting models are new supported. Supports fine-tuning and inference for four models: [fsmn_kws](https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online), [fsmn_kws_mt](https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online), [sanm_kws](https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-offline), [sanm_kws_streaming](https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online).
41:- 2024/07/04：[SenseVoice](https://github.com/FunAudioLLM/SenseVoice) is a speech foundation model with multiple speech understanding capabilities, including ASR, LID, SER, and AED.
42:- 2024/07/01: Offline File Transcription Service GPU 1.1 released, optimize BladeDISC model compatibility issues; ref to ([docs](runtime/readme.md))
43:- 2024/06/27: Offline File Transcription Service GPU 1.0 released, supporting dynamic batch processing and multi-threading concurrency. In the long audio test set, the single-thread RTF is 0.0076, and multi-threads' speedup is 1200+ (compared to 330+ on CPU); ref to ([docs](runtime/readme.md))
44:- 2024/05/15：emotion recognition models are new supported. [emotion2vec+large](https://modelscope.cn/models/iic/emotion2vec_plus_large/summary)，[emotion2vec+base](https://modelscope.cn/models/iic/emotion2vec_plus_base/summary)，[emotion2vec+seed](https://modelscope.cn/models/iic/emotion2vec_plus_seed/summary). currently supports the following categories: 0: angry 1: happy 2: neutral 3: sad 4: unknown.
45:- 2024/05/15: Offline File Transcription Service 4.5, Offline File Transcription Service of English 1.6, Real-time Transcription Service 1.10 released, adapting to FunASR 1.0 model structure；([docs](runtime/readme.md))
46:
47:<details><summary>Full Changelog</summary>
48:
49:- 2024/03/05：Added the Qwen-Audio and Qwen-Audio-Chat large-scale audio-text multimodal models, which have topped multiple audio domain leaderboards. These models support speech dialogue, [usage](examples/industrial_data_pretraining/qwen_audio).
50:- 2024/03/05：Added support for the Whisper-large-v3 model, a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. It can be downloaded from the[modelscope](examples/industrial_data_pretraining/whisper/demo.py), and [openai](examples/industrial_data_pretraining/whisper/demo_from_openai.py).
51:- 2024/03/05: Offline File Transcription Service 4.4, Offline File Transcription Service of English 1.5，Real-time Transcription Service 1.9 released，docker image supports ARM64 platform, update modelscope；([docs](runtime/readme.md))
52:- 2024/01/30：funasr-1.0 has been released ([docs](https://github.com/alibaba-damo-academy/FunASR/discussions/1319))
53:- 2024/01/30：emotion recognition models are new supported. [model link](https://www.modelscope.cn/models/iic/emotion2vec_base_finetuned/summary), modified from [repo](https://github.com/ddlBoJack/emotion2vec).
54:- 2024/01/25: Offline File Transcription Service 4.2, Offline File Transcription Service of English 1.3 released，optimized the VAD (Voice Activity Detection) data processing method, significantly reducing peak memory usage, memory leak optimization; Real-time Transcription Service 1.7 released，optimizatized the client-side；([docs](runtime/readme.md))
55:- 2024/01/09: The Funasr SDK for Windows version 2.0 has been released, featuring support for The offline file transcription service (CPU) of Mandarin 4.1, The offline file transcription service (CPU) of English 1.2, The real-time transcription service (CPU) of Mandarin 1.6. For more details, please refer to the official documentation or release notes([FunASR-Runtime-Windows](https://www.modelscope.cn/models/damo/funasr-runtime-win-cpu-x64/summary))
56:- 2024/01/03: File Transcription Service 4.0 released, Added support for 8k models, optimized timestamp mismatch issues and added sentence-level timestamps, improved the effectiveness of English word FST hotwords, supported automated configuration of thread parameters, and fixed known crash issues as well as memory leak problems, refer to ([docs](runtime/readme.md#file-transcription-service-mandarin-cpu)).
57:- 2024/01/03: Real-time Transcription Service 1.6 released，The 2pass-offline mode supports Ngram language model decoding and WFST hotwords, while also addressing known crash issues and memory leak problems, ([docs](runtime/readme.md#the-real-time-transcription-service-mandarin-cpu))
58:- 2024/01/03: Fixed known crash issues as well as memory leak problems, ([docs](runtime/readme.md#file-transcription-service-english-cpu)).
59:- 2023/12/04: The Funasr SDK for Windows version 1.0 has been released, featuring support for The offline file transcription service (CPU) of Mandarin, The offline file transcription service (CPU) of English, The real-time transcription service (CPU) of Mandarin. For more details, please refer to the official documentation or release notes([FunASR-Runtime-Windows](https://www.modelscope.cn/models/damo/funasr-runtime-win-cpu-x64/summary))
60:- 2023/11/08: The offline file transcription service 3.0 (CPU) of Mandarin has been released, adding punctuation large model, Ngram language model, and wfst hot words. For detailed information, please refer to [docs](runtime#file-transcription-service-mandarin-cpu). 
61:- 2023/10/17: The offline file transcription service (CPU) of English has been released. For more details, please refer to ([docs](runtime#file-transcription-service-english-cpu)).
62:- 2023/10/13: [SlideSpeech](https://slidespeech.github.io/): A large scale multi-modal audio-visual corpus with a significant amount of real-time synchronized slides.
63:- 2023/10/10: The ASR-SpeakersDiarization combined pipeline [Paraformer-VAD-SPK](https://github.com/alibaba-damo-academy/FunASR/blob/main/egs_modelscope/asr_vad_spk/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn/demo.py) is now released. Experience the model to get recognition results with speaker information.
64:- 2023/10/07: [FunCodec](https://github.com/alibaba-damo-academy/FunCodec): A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec.
65:- 2023/09/01: The offline file transcription service 2.0 (CPU) of Mandarin has been released, with added support for ffmpeg, timestamp, and hotword models. For more details, please refer to ([docs](runtime#file-transcription-service-mandarin-cpu)).
66:- 2023/08/07: The real-time transcription service (CPU) of Mandarin has been released. For more details, please refer to ([docs](runtime#the-real-time-transcription-service-mandarin-cpu)).
67:- 2023/07/17: BAT is released, which is a low-latency and low-memory-consumption RNN-T model. For more details, please refer to ([BAT](egs/aishell/bat)).
68:- 2023/06/26: ASRU2023 Multi-Channel Multi-Party Meeting Transcription Challenge 2.0 completed the competition and announced the results. For more details, please refer to ([M2MeT2.0](https://alibaba-damo-academy.github.io/FunASR/m2met2/index.html)).
69:
70:</details>
71:
72:<a name="Installation"></a>
73:## Installation
74:
75:- Requirements
76:```text
77:python>=3.8
78:torch>=1.13
79:torchaudio
80:```
81:
82:- Install for pypi
83:```shell
84:pip3 install -U funasr
85:```
86:- Or install from source code
87:``` sh
88:git clone https://github.com/alibaba/FunASR.git && cd FunASR
89:pip3 install -e ./
90:```
91:- Install modelscope or huggingface_hub for the pretrained models (Optional)
92:
93:```shell
94:pip3 install -U modelscope huggingface_hub
95:```
96:
97:## Model Zoo
98:FunASR has open-sourced a large number of pre-trained models on industrial data. You are free to use, copy, modify, and share FunASR models under the [Model License Agreement](./MODEL_LICENSE). Below are some representative models, for more models please refer to the [Model Zoo](./model_zoo).
99:
100:(Note: ⭐ represents the ModelScope model zoo, 🤗 represents the Huggingface model zoo, 🍀 represents the OpenAI model zoo)
(291 more lines below)
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/README.md)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:44:52,434 - INFO - swea-agent - ========================= STEP 2 =========================
2025-05-12 15:44:52,444 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:45:04,922 - INFO - swea-lm - Response: ModelResponse(id='021747035892476c2533d56d1ae70a6cfff862835e0834d39add8', created=1747035904, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `README.md` provides an overview of the FunASR toolkit, including its features, installation instructions, and model zoo. To proceed, we need to:\n\n1. **Install FunASR**: The `README.md` suggests installing FunASR via `pip` or from source. Since we cannot install packages in this environment, we will assume the toolkit is already installed or use the provided scripts directly.\n\n2. **Use the Toolkit**: The `README.md` mentions that FunASR supports speech recognition (ASR) and provides pre-trained models. We need to locate the script or example that performs ASR on an audio file.\n\n3. **Locate the ASR Script**: Let's search for example scripts or main entry points in the FunASR repository that handle ASR.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"file_name":"*.py", "dir":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR"}', name='find_file'), id='call_gz1redb1h1nwpd7w7pjc29ca', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=204, prompt_tokens=15342, total_tokens=15546, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:45:04,932 - INFO - swea-agent - 💭 THOUGHT
The `README.md` provides an overview of the FunASR toolkit, including its features, installation instructions, and model zoo. To proceed, we need to:

1. **Install FunASR**: The `README.md` suggests installing FunASR via `pip` or from source. Since we cannot install packages in this environment, we will assume the toolkit is already installed or use the provided scripts directly.

2. **Use the Toolkit**: The `README.md` mentions that FunASR supports speech recognition (ASR) and provides pre-trained models. We need to locate the script or example that performs ASR on an audio file.

3. **Locate the ASR Script**: Let's search for example scripts or main entry points in the FunASR repository that handle ASR.

🎬 ACTION
find_file '*.py' /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
2025-05-12 15:45:05,241 - INFO - swea-agent - 🤖 MODEL INPUT
Observation: Found 1158 matches for "*.py" in /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR:
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/docs/conf.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/docs/m2met2/conf.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/compute_wer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/extract_embeds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/postprocess_text_zh.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/text2token.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/text_tokenize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/textnorm_zh.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/compute_wer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/extract_embeds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/postprocess_text_zh.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/text2token.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/text_tokenize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/textnorm_zh.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/common_voice/whisper_lid/demo_funasr.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/common_voice/whisper_lid/demo_modelscope.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/bicif_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/bicif_paraformer/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/campplus_sv/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/conformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/contextual_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer_streaming/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ctc/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/convert.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/convert.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_vad_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_vad_streaming/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/lcbnet/compute_wer_details.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/lcbnet/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/app.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_speech2text.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_speech2text_multi.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_speech2text_multi_stream.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/monotonic_aligner/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer-zh-spk/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer-zh-spk/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer_streaming/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo_chat.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo_chat_from_local.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo_from_local.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/scama/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/seaco_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/demo_libtorch.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/demo_onnx.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/transducer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/uniasr/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/whisper/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/whisper/demo_from_openai.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/export_models.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/measurements/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/roman/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/inverse_normalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/char/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/preprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/decimals.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/run_evaluate.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/math/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/data_loader_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/measure/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/months/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/address/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/date/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/measure/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/number/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/ordinal/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/roman/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/telephone/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/whitelist/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/abbreviation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/range.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/roman.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/serial.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/tokenize_and_classify_lm.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/tokenize_and_classify_with_audio.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/abbreviation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/post_processing.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/roman.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/dates/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/fractions/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/measures/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/roman/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/decimals.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/decimals.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/export_models.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/normalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/normalize_with_audio.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/alphabet.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/currency/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/months/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/utils/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/decimals.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/number_names.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/run_evaluate.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/token_parser.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/char/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/date/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/denylist/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/erhua/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/math/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/measure/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/number/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/whitelist/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/char.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/math_symbol.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/preprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/char.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/math_symbol.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/postprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/auto_frontend.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/auto_model.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/auto_tokenizer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/compute_audio_cmvn.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/tokenize_text.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/train.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/train_ds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/espnet_samplers.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/index_ds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/jsonl2scp.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/preprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/samplers.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/scp2jsonl.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/scp2len.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/sensevoice2jsonl.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/update_jsonl.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/dataloader_entry.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/kws_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/kws_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets/preprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets_qwenaudio/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets_qwenaudio/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets_vicuna/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets_vicuna/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/openai_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/openai_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/openai_datasets/index_ds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/sense_voice_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/sense_voice_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/download_dataset_from_hub.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/download_model_from_hub.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/file.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/name_maps_from_hub.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/runtime_sdk_download_tool.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/default.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/eend_ola_feature.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/fused.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/s3prl.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/beamformer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/complex_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/dnn_beamformer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/dnn_wpe.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/feature_transform.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/frontend.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/log_mel.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/mask_estimator.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/stft.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/wav_frontend.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/whisper_frontend.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/windowing.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/losses/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/losses/label_smoothing_loss.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/common.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/compute_acc.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/compute_eer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/compute_min_dcf.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/wer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bat/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bat/model.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/cif_predictor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/export_meta.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/model.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/cgmlp.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/encoder.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/fastformer.py
/data/data/agent_test_codebase/GitTaskBench<response clipped><NOTE>Observations should not exceeded 100000 characters. 37651 characters were elided. Please try a different command that produces less output or use head/tail/grep/redirect the output to a file. Do not use interactive pagers.</NOTE>
2025-05-12 15:45:05,304 - INFO - swea-agent - ========================= STEP 3 =========================
2025-05-12 15:45:05,326 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:45:23,259 - INFO - swea-lm - Response: ModelResponse(id='021747035905367e54042c903da3a08a41d73404311af53538b61', created=1747035923, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The repository contains many Python files, but we are particularly interested in the `inference.py` script located at `/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py`, as it is likely the main script for performing speech recognition. Let's open this file to understand how to use it for our task.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"path":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py"}', name='open'), id='call_uqyoapg6qr7igsdeyi3v7aqq', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=118, prompt_tokens=44730, total_tokens=44848, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:45:23,267 - INFO - swea-agent - 💭 THOUGHT
The repository contains many Python files, but we are particularly interested in the `inference.py` script located at `/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py`, as it is likely the main script for performing speech recognition. Let's open this file to understand how to use it for our task.

🎬 ACTION
open "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py"
2025-05-12 15:45:23,752 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py (30 lines total)]
1:import hydra
2:import logging
3:from omegaconf import DictConfig, OmegaConf, ListConfig
4:
5:from funasr.auto.auto_model import AutoModel
6:
7:
8:@hydra.main(config_name=None, version_base=None)
9:def main_hydra(cfg: DictConfig):
10:    def to_plain_list(cfg_item):
11:        if isinstance(cfg_item, ListConfig):
12:            return OmegaConf.to_container(cfg_item, resolve=True)
13:        elif isinstance(cfg_item, DictConfig):
14:            return {k: to_plain_list(v) for k, v in cfg_item.items()}
15:        else:
16:            return cfg_item
17:
18:    kwargs = to_plain_list(cfg)
19:
20:    if kwargs.get("debug", False):
21:        import pdb
22:
23:        pdb.set_trace()
24:    model = AutoModel(**kwargs)
25:    res = model.generate(input=kwargs["input"])
26:    print(res)
27:
28:
29:if __name__ == "__main__":
30:    main_hydra()
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:45:23,761 - INFO - swea-agent - ========================= STEP 4 =========================
2025-05-12 15:45:23,783 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:45:42,220 - INFO - swea-lm - Response: ModelResponse(id='021747035923823d9f2b6f781bd0539f58fa26888d288808a0193', created=1747035942, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `inference.py` script uses the `AutoModel` class from `funasr.auto.auto_model` to perform speech recognition. The script takes a configuration file (`cfg`) as input and processes the input audio file specified in the configuration. \n\n### Next Steps:\n1. **Understand the Configuration**: The script requires a configuration file (`cfg`) to specify the model and input file. We need to find an example configuration or understand how to create one.\n2. **Locate Example Configurations**: Let's search for example configuration files in the repository.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"file_name":"*.yaml", "dir":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR"}', name='find_file'), id='call_2jplp2xvm71gixk4576qs0t3', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=159, prompt_tokens=45310, total_tokens=45469, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:45:42,229 - INFO - swea-agent - 💭 THOUGHT
The `inference.py` script uses the `AutoModel` class from `funasr.auto.auto_model` to perform speech recognition. The script takes a configuration file (`cfg`) as input and processes the input audio file specified in the configuration. 

### Next Steps:
1. **Understand the Configuration**: The script requires a configuration file (`cfg`) to specify the model and input file. We need to find an example configuration or understand how to create one.
2. **Locate Example Configurations**: Let's search for example configuration files in the repository.

🎬 ACTION
find_file '*.yaml' /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
2025-05-12 15:45:42,508 - INFO - swea-agent - 🤖 MODEL INPUT
Found 44 matches for "*.yaml" in /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR:
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/.github/ISSUE_TEMPLATE/config.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/.pre-commit-config.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/branchformer/conf/branchformer_12e_6d_2048_256.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/conformer/conf/conformer_12e_6d_2048_256.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/conformer/conf/conformer_rwkv.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_branchformer/conf/e_branchformer_12e_6d_2048_256.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/conf/e_paraformer_conformer_12e_6d_2048_256.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/conf/paraformer_conformer_12e_6d_2048_256.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/transformer/conf/transformer_12e_6d_2048_256.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/conf/fsmn_4e_l10r2_250_128_fdim80_t2599.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/conf/fsmn_4e_l10r2_280_200_fdim40_t2602.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/conf/fsmn_4e_l10r2_250_128_fdim80_t2599_t4.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/conf/fsmn_4e_l10r2_280_200_fdim40_t2602_t4.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/conf/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/conf/whisper_qwen_linear.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/conf/whisper_qwen_linear2.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/conf/whisper_qwen_transformer.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/conf/whisper_vicuna_linear.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/conf/sanm_6e_320_256_fdim40_t2602.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/conf/sanm_6e_320_256_fdim40_t2602.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/wenetspeech/conformer/conf/conformer_12e_6d_2048_512.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/campplus/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/conformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/conformer_rwkv/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/contextual_paraformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/ct_transformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/ct_transformer_streaming/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/e_branchformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/fsmn_vad_streaming/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/monotonic_aligner/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/paraformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/paraformer_streaming/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/qwen_audio/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/rwkv_bat/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/sanm/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/scama/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/seaco_paraformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/transformer/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/uniasr/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/whisper/template.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/triton_gpu/model_repo_paraformer_large_online/feature_extractor/config.yaml
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/triton_gpu/model_repo_sense_voice_small/feature_extractor/config.yaml
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:45:42,519 - INFO - swea-agent - ========================= STEP 5 =========================
2025-05-12 15:45:42,541 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:45:59,440 - INFO - swea-lm - Response: ModelResponse(id='021747035942585877b79ccd965086b7c0f04f8d6f379a1f88b0e', created=1747035959, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The repository contains several YAML configuration files, but they are mostly model-specific. We need a simpler configuration to run the `inference.py` script with our input audio file. Let's create a minimal configuration file to specify the input audio file and the model to use.\n\n### Step 1: Create a Configuration File\nWe'll create a new YAML file named `config.yaml` in the current directory to specify the input audio file and the model.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"filename":"config.yaml"}', name='create'), id='call_7kzxymvv3q482rtvfynal2g0', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=110, prompt_tokens=47258, total_tokens=47368, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:45:59,449 - INFO - swea-agent - 💭 THOUGHT
The repository contains several YAML configuration files, but they are mostly model-specific. We need a simpler configuration to run the `inference.py` script with our input audio file. Let's create a minimal configuration file to specify the input audio file and the model to use.

### Step 1: Create a Configuration File
We'll create a new YAML file named `config.yaml` in the current directory to specify the input audio file and the model.

🎬 ACTION
create config.yaml
2025-05-12 15:45:59,933 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: config.yaml (1 lines total)]
1:
(Open file: /GitTaskBench/config.yaml)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:45:59,943 - INFO - swea-agent - ========================= STEP 6 =========================
2025-05-12 15:45:59,965 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:46:19,601 - INFO - swea-lm - Response: ModelResponse(id='021747035960004f8b29abe63ea4b2d80e0e367632786e9ca955f', created=1747035979, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="Now, let's insert the configuration content into the `config.yaml` file. The configuration should specify the input audio file (`/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav`) and the model to use (e.g., `speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch`).", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"text":"input: /data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav\\nmodel: speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"}', name='insert'), id='call_o5k64ti8je52mjleroagzjt2', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=174, prompt_tokens=47481, total_tokens=47655, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:46:19,610 - INFO - swea-agent - 💭 THOUGHT
Now, let's insert the configuration content into the `config.yaml` file. The configuration should specify the input audio file (`/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav`) and the model to use (e.g., `speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch`).

🎬 ACTION
insert 'input: /data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav
model: speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch'
2025-05-12 15:46:20,114 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /GitTaskBench/config.yaml (3 lines total)]
1:
2:input: /data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav
3:model: speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch
(Open file: /GitTaskBench/config.yaml)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:46:20,125 - INFO - swea-agent - ========================= STEP 7 =========================
2025-05-12 15:46:20,147 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:46:38,363 - INFO - swea-lm - Response: ModelResponse(id='02174703598018916b977401f4df41f54664316aeb6668ec34478', created=1747035998, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The configuration file is now ready. Next, we need to run the `inference.py` script with this configuration file. However, the script is located in the FunASR repository, so we need to ensure we are in the correct directory or provide the full path to the script.\n\n### Step 2: Run the Inference Script\nLet's run the `inference.py` script with the `config.yaml` file. We'll use the full path to the script and the configuration file.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"python /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py config.yaml"}', name='bash'), id='call_de2fl0b7ji2p724pzg4hp5c4', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=145, prompt_tokens=44300, total_tokens=44445, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:46:38,372 - INFO - swea-agent - 💭 THOUGHT
The configuration file is now ready. Next, we need to run the `inference.py` script with this configuration file. However, the script is located in the FunASR repository, so we need to ensure we are in the correct directory or provide the full path to the script.

### Step 2: Run the Inference Script
Let's run the `inference.py` script with the `config.yaml` file. We'll use the full path to the script and the configuration file.

🎬 ACTION
python /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py config.yaml
2025-05-12 15:46:38,665 - INFO - swea-agent - 🤖 MODEL INPUT
Traceback (most recent call last):
  File "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py", line 1, in <module>
    import hydra
ModuleNotFoundError: No module named 'hydra'
(Open file: /GitTaskBench/config.yaml)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:46:38,678 - INFO - swea-agent - ========================= STEP 8 =========================
2025-05-12 15:46:38,688 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:46:47,338 - INFO - swea-lm - Response: ModelResponse(id='021747035998720c3dbaef3e90dd8e661a64b6f58e4da685316a3', created=1747036007, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The error indicates that the `hydra` module is not installed. Since we cannot install packages in this environment, we need to find an alternative way to run the script or use a different script that does not require `hydra`.\n\n### Step 3: Locate an Alternative Script\nLet's search for other scripts in the FunASR repository that might perform speech recognition without requiring `hydra`.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"file_name":"*.py", "dir":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR"}', name='find_file'), id='call_6dpocqx6jmmnczbm7kide2f4', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=124, prompt_tokens=15364, total_tokens=15488, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:46:47,346 - INFO - swea-agent - 💭 THOUGHT
The error indicates that the `hydra` module is not installed. Since we cannot install packages in this environment, we need to find an alternative way to run the script or use a different script that does not require `hydra`.

### Step 3: Locate an Alternative Script
Let's search for other scripts in the FunASR repository that might perform speech recognition without requiring `hydra`.

🎬 ACTION
find_file '*.py' /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
2025-05-12 15:46:47,649 - INFO - swea-agent - 🤖 MODEL INPUT
Observation: Found 1158 matches for "*.py" in /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR:
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/docs/conf.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/docs/m2met2/conf.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/compute_wer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/extract_embeds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/postprocess_text_zh.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/text2token.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/text_tokenize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/textnorm_zh.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/compute_wer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/extract_embeds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/postprocess_text_zh.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/text2token.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/text_tokenize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/textnorm_zh.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/common_voice/whisper_lid/demo_funasr.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/common_voice/whisper_lid/demo_modelscope.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/bicif_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/bicif_paraformer/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/campplus_sv/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/conformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/contextual_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer_streaming/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ctc/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/convert.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/convert.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_vad_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_vad_streaming/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/lcbnet/compute_wer_details.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/lcbnet/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/app.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_speech2text.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_speech2text_multi.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_speech2text_multi_stream.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/monotonic_aligner/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer-zh-spk/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer-zh-spk/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer_streaming/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo_chat.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo_chat_from_local.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo_from_local.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/scama/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/seaco_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/demo_libtorch.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/demo_onnx.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/transducer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/uniasr/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/whisper/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/whisper/demo_from_openai.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/de/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/en/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/es/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/export_models.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/measurements/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/roman/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/fr/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/id/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/inverse_normalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/char/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/preprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ja/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ko/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/pt/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/decimals.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/ru/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/run_evaluate.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/tl/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/math/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/vi/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/inverse_text_normalization/zh/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/data_loader_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/measure/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/months/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/de/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/clean_eval_data.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/address/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/date/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/measure/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/number/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/ordinal/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/roman/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/telephone/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/data/whitelist/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/abbreviation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/punctuation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/range.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/roman.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/serial.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/tokenize_and_classify_lm.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/tokenize_and_classify_with_audio.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/abbreviation.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/post_processing.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/roman.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/en/verbalizers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/dates/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/fractions/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/measures/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/ordinals/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/roman/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/decimals.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/decimals.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/es/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/export_models.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/normalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/normalize_with_audio.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/alphabet.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/currency/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/electronic/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/months/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/numbers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/data/utils/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/decimals.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/number_names.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/taggers/word.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/decimal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/electronic.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/ordinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/telephone.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/ru/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/run_evaluate.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/token_parser.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/char/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/date/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/denylist/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/erhua/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/math/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/measure/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/money/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/number/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/time/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/data/whitelist/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/graph_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/char.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/math_symbol.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/preprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/tokenize_and_classify.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/taggers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/cardinal.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/char.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/date.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/fraction.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/math_symbol.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/measure.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/money.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/postprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/time.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/verbalize.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/verbalize_final.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/text_normalization/zh/verbalizers/whitelist.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/auto_frontend.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/auto_model.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/auto/auto_tokenizer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/compute_audio_cmvn.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/export.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/inference.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/tokenize_text.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/train.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/bin/train_ds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/espnet_samplers.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/index_ds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/jsonl2scp.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/preprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/samplers.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/scp2jsonl.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/scp2len.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/sensevoice2jsonl.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/audio_datasets/update_jsonl.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/dataloader_entry.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/kws_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/kws_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets/preprocessor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets_qwenaudio/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets_qwenaudio/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets_vicuna/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/llm_datasets_vicuna/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/openai_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/openai_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/openai_datasets/index_ds.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/sense_voice_datasets/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/datasets/sense_voice_datasets/datasets.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/download_dataset_from_hub.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/download_model_from_hub.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/file.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/name_maps_from_hub.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/download/runtime_sdk_download_tool.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/default.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/eend_ola_feature.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/fused.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/s3prl.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/beamformer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/complex_utils.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/dnn_beamformer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/dnn_wpe.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/feature_transform.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/frontend.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/log_mel.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/mask_estimator.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/utils/stft.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/wav_frontend.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/whisper_frontend.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/frontends/windowing.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/losses/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/losses/label_smoothing_loss.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/common.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/compute_acc.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/compute_eer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/compute_min_dcf.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/metrics/wer.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bat/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bat/model.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/cif_predictor.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/export_meta.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/bicif_paraformer/model.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/__init__.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/cgmlp.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/encoder.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/funasr/models/branchformer/fastformer.py
/data/data/agent_test_codebase/GitTaskBench<response clipped><NOTE>Observations should not exceeded 100000 characters. 37651 characters were elided. Please try a different command that produces less output or use head/tail/grep/redirect the output to a file. Do not use interactive pagers.</NOTE>
2025-05-12 15:46:47,711 - INFO - swea-agent - ========================= STEP 9 =========================
2025-05-12 15:46:47,733 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:47:03,089 - INFO - swea-lm - Response: ModelResponse(id='021747036007778103b2db096abf9f869caef254a754061c6b07b', created=1747036023, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The repository contains many Python files, but we are particularly interested in the `demo.py` scripts located in various directories, as they might provide examples of how to use the FunASR toolkit for speech recognition. Let's look for a `demo.py` script in the repository.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"file_name":"demo.py", "dir":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR"}', name='find_file'), id='call_jrb98pqg19rt4ixq58hrne41', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=99, prompt_tokens=44228, total_tokens=44327, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:47:03,098 - INFO - swea-agent - 💭 THOUGHT
The repository contains many Python files, but we are particularly interested in the `demo.py` scripts located in various directories, as they might provide examples of how to use the FunASR toolkit for speech recognition. Let's look for a `demo.py` script in the repository.

🎬 ACTION
find_file demo.py /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
2025-05-12 15:47:03,377 - INFO - swea-agent - 🤖 MODEL INPUT
Found 24 matches for "demo.py" in /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR:
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/bicif_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/campplus_sv/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/conformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/contextual_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ctc/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_vad_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/lcbnet/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/monotonic_aligner/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer-zh-spk/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/qwen_audio/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/scama/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/seaco_paraformer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/transducer/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/uniasr/demo.py
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/whisper/demo.py
(Open file: /GitTaskBench/config.yaml)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:47:03,393 - INFO - swea-agent - ========================= STEP 10 =========================
2025-05-12 15:47:03,414 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:47:17,539 - INFO - swea-lm - Response: ModelResponse(id='021747036023455c2533d56d1ae70a6cfff862835e0834d458d37', created=1747036037, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="Let's open the `demo.py` script from the `paraformer` directory, as it might be a good example of how to use the toolkit for speech recognition.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"path":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py"}', name='open'), id='call_4ofajdp3rad1bqsemnefm2x9', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=83, prompt_tokens=43466, total_tokens=43549, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:47:17,547 - INFO - swea-agent - 💭 THOUGHT
Let's open the `demo.py` script from the `paraformer` directory, as it might be a good example of how to use the toolkit for speech recognition.

🎬 ACTION
open "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py"
2025-05-12 15:47:18,044 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py (47 lines total)]
1:#!/usr/bin/env python3
2:# -*- encoding: utf-8 -*-
3:# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
4:#  MIT License  (https://opensource.org/licenses/MIT)
5:
6:from funasr import AutoModel
7:
8:model = AutoModel(
9:    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
10:    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
11:    vad_kwargs={"max_single_segment_time": 60000},
12:    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
13:    # spk_model="iic/speech_campplus_sv_zh-cn_16k-common",
14:)
15:
16:res = model.generate(
17:    input="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav",
18:    cache={},
19:)
20:
21:print(res)
22:
23:
24:""" call english model like below for detailed timestamps
25:# choose english paraformer model first
26:# iic/speech_paraformer_asr-en-16k-vocab4199-pytorch
27:res = model.generate(
28:    input="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_en.wav",
29:    cache={},
30:    pred_timestamp=True,
31:    return_raw_text=True,
32:    sentence_timestamp=True,
33:    en_post_proc=True,
34:)
35:"""
36:
37:""" can not use currently
38:from funasr import AutoFrontend
39:
40:frontend = AutoFrontend(model="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch")
41:
42:fbanks = frontend(input="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav", batch_size=2)
43:
44:for batch_idx, fbank_dict in enumerate(fbanks):
45:    res = model.generate(**fbank_dict)
46:    print(res)
47:"""
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/demo.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:47:18,063 - INFO - swea-agent - ========================= STEP 11 =========================
2025-05-12 15:47:18,084 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:47:38,908 - INFO - swea-lm - Response: ModelResponse(id='021747036038119c3dbaef3e90dd8e661a64b6f58e4da68a1ef49', created=1747036058, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `demo.py` script demonstrates how to use the `AutoModel` class from the `funasr` module to perform speech recognition. It loads a pre-trained model and processes an input audio file. \n\n### Next Steps:\n1. **Modify the Script**: We can modify this script to use our input audio file (`/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav`) and save the output to the specified directory (`/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01`).\n\n2. **Create a New Script**: Let's create a new script called `run_asr.py` to perform the speech recognition task.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"filename":"run_asr.py"}', name='create'), id='call_ztgc9vggy90jkd9yt7v2n4uf', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=182, prompt_tokens=44292, total_tokens=44474, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:47:38,917 - INFO - swea-agent - 💭 THOUGHT
The `demo.py` script demonstrates how to use the `AutoModel` class from the `funasr` module to perform speech recognition. It loads a pre-trained model and processes an input audio file. 

### Next Steps:
1. **Modify the Script**: We can modify this script to use our input audio file (`/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav`) and save the output to the specified directory (`/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01`).

2. **Create a New Script**: Let's create a new script called `run_asr.py` to perform the speech recognition task.

🎬 ACTION
create run_asr.py
2025-05-12 15:47:39,428 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: run_asr.py (1 lines total)]
1:
(Open file: /GitTaskBench/run_asr.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:47:39,447 - INFO - swea-agent - ========================= STEP 12 =========================
2025-05-12 15:47:39,469 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:48:09,896 - INFO - swea-lm - Response: ModelResponse(id='0217470360595118ce1e7042c8a3994a70c7ec0e7dd433fbfb394', created=1747036089, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="Now, let's insert the code into `run_asr.py` to perform speech recognition on our input audio file and save the output.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"text":"#!/usr/bin/env python3\\n# -*- encoding: utf-8 -*-\\n# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.\\n#  MIT License  (https://opensource.org/licenses/MIT)\\n\\nfrom funasr import AutoModel\\nimport os\\n\\n# Define input and output paths\\ninput_audio = \\"/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav\\"\\noutput_dir = \\"/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01\\"\\n\\n# Ensure output directory exists\\nos.makedirs(output_dir, exist_ok=True)\\n\\n# Initialize the model\\nmodel = AutoModel(\\n    model=\\"iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\\",\\n    vad_model=\\"iic/speech_fsmn_vad_zh-cn-16k-common-pytorch\\",\\n    vad_kwargs={\\"max_single_segment_time\\": 60000},\\n    punc_model=\\"iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch\\",\\n)\\n\\n# Perform speech recognition\\nresult = model.generate(\\n    input=input_audio,\\n    cache={},\\n)\\n\\n# Save the result to a file\\noutput_file = os.path.join(output_dir, \\"output.txt\\")\\nwith open(output_file, \\"w\\") as f:\\n    f.write(str(result))\\n\\nprint(f\\"Speech recognition completed. Result saved to {output_file}\\")"}', name='insert'), id='call_eb8usuqbc7nj17ohum7mktg9', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=429, prompt_tokens=44420, total_tokens=44849, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:48:09,906 - INFO - swea-agent - 💭 THOUGHT
Now, let's insert the code into `run_asr.py` to perform speech recognition on our input audio file and save the output.

🎬 ACTION
insert '#!/usr/bin/env python3
# -*- encoding: utf-8 -*-
# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
#  MIT License  (https://opensource.org/licenses/MIT)

from funasr import AutoModel
import os

# Define input and output paths
input_audio = "/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
output_dir = "/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"

# Ensure output directory exists
os.makedirs(output_dir, exist_ok=True)

# Initialize the model
model = AutoModel(
    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
    vad_kwargs={"max_single_segment_time": 60000},
    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
)

# Perform speech recognition
result = model.generate(
    input=input_audio,
    cache={},
)

# Save the result to a file
output_file = os.path.join(output_dir, "output.txt")
with open(output_file, "w") as f:
    f.write(str(result))

print(f"Speech recognition completed. Result saved to {output_file}")'
2025-05-12 15:48:10,832 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /GitTaskBench/run_asr.py (36 lines total)]
1:
2:#!/usr/bin/env python3
3:# -*- encoding: utf-8 -*-
4:# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
5:#  MIT License  (https://opensource.org/licenses/MIT)
6:
7:from funasr import AutoModel
8:import os
9:
10:# Define input and output paths
11:input_audio = "/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
12:output_dir = "/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
13:
14:# Ensure output directory exists
15:os.makedirs(output_dir, exist_ok=True)
16:
17:# Initialize the model
18:model = AutoModel(
19:    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
20:    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
21:    vad_kwargs={"max_single_segment_time": 60000},
22:    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
23:)
24:
25:# Perform speech recognition
26:result = model.generate(
27:    input=input_audio,
28:    cache={},
29:)
30:
31:# Save the result to a file
32:output_file = os.path.join(output_dir, "output.txt")
33:with open(output_file, "w") as f:
34:    f.write(str(result))
35:
36:print(f"Speech recognition completed. Result saved to {output_file}")
(Open file: /GitTaskBench/run_asr.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:48:10,853 - INFO - swea-agent - ========================= STEP 13 =========================
2025-05-12 15:48:10,875 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:48:26,390 - INFO - swea-lm - Response: ModelResponse(id='021747036090917c3dbaef3e90dd8e661a64b6f58e4da6820c156', created=1747036106, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='The script `run_asr.py` is now ready. It will:\n1. Load the pre-trained speech recognition model.\n2. Process the input audio file.\n3. Save the transcription result to the specified output directory.\n\n### Next Steps:\n1. **Run the Script**: Execute the script to perform speech recognition.', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"python run_asr.py"}', name='bash'), id='call_folwuo3eury0prxettc22r3v', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=85, prompt_tokens=45361, total_tokens=45446, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:48:26,399 - INFO - swea-agent - 💭 THOUGHT
The script `run_asr.py` is now ready. It will:
1. Load the pre-trained speech recognition model.
2. Process the input audio file.
3. Save the transcription result to the specified output directory.

### Next Steps:
1. **Run the Script**: Execute the script to perform speech recognition.

🎬 ACTION
python run_asr.py
2025-05-12 15:48:26,695 - INFO - swea-agent - 🤖 MODEL INPUT
Traceback (most recent call last):
  File "/GitTaskBench/run_asr.py", line 7, in <module>
    from funasr import AutoModel
ModuleNotFoundError: No module named 'funasr'
(Open file: /GitTaskBench/run_asr.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:48:26,717 - INFO - swea-agent - ========================= STEP 14 =========================
2025-05-12 15:48:26,728 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:48:37,325 - INFO - swea-lm - Response: ModelResponse(id='021747036106760877b79ccd965086b7c0f04f8d6f379a1f9c537', created=1747036117, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The error indicates that the `funasr` module is not installed in the current environment. Since we cannot install packages in this environment, we need to find an alternative way to run the script or use a different approach.\n\n### Alternative Approach:\n1. **Check for Pre-installed Scripts**: The FunASR repository might have pre-installed scripts or executables that can be run directly without requiring the `funasr` module.\n\n2. **Locate Executable Scripts**: Let's search for executable scripts in the FunASR repository that might perform speech recognition.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"file_name":"*.sh", "dir":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR"}', name='find_file'), id='call_wyz4z3o0085uemyos8kq27b1', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=160, prompt_tokens=16358, total_tokens=16518, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:48:37,336 - INFO - swea-agent - 💭 THOUGHT
The error indicates that the `funasr` module is not installed in the current environment. Since we cannot install packages in this environment, we need to find an alternative way to run the script or use a different approach.

### Alternative Approach:
1. **Check for Pre-installed Scripts**: The FunASR repository might have pre-installed scripts or executables that can be run directly without requiring the `funasr` module.

2. **Locate Executable Scripts**: Let's search for executable scripts in the FunASR repository that might perform speech recognition.

🎬 ACTION
find_file '*.sh' /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
2025-05-12 15:48:37,621 - INFO - swea-agent - 🤖 MODEL INPUT
Found 120 matches for "*.sh" in /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR:
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/branchformer/infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/branchformer/local/aishell_data_prep.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/branchformer/local/download_and_untar.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/branchformer/run.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/conformer/local/aishell_data_prep.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/conformer/local/download_and_untar.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/conformer/run.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_branchformer/local/aishell_data_prep.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_branchformer/local/download_and_untar.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_branchformer/run.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/demo_infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/demo_train_or_finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/local/aishell_data_prep.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/local/download_and_untar.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/run.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/fix_data.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/fix_data_feat.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/parse_options.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/e_paraformer/utils/text_tokenize.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/demo_infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/demo_train_or_finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/local/aishell_data_prep.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/local/download_and_untar.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/run.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/fix_data.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/fix_data_feat.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/parse_options.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/paraformer/utils/text_tokenize.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/transformer/local/aishell_data_prep.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/transformer/local/download_and_untar.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/aishell/transformer/run.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/bicif_paraformer/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/bicif_paraformer/export.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/bicif_paraformer/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/conformer/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/contextual_paraformer/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/contextual_paraformer/demo2.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/contextual_paraformer/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/contextual_paraformer/path.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer/export.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer_streaming/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ct_transformer_streaming/export.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/ctc/infer_from_local.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/convert.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/infer_from_local.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws/path.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/convert.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/infer_from_local.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_kws_mt/path.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_vad_streaming/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/fsmn_vad_streaming/export.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/lcbnet/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/lcbnet/run_bwer_recall.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_speech2text.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_train_or_finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/demo_train_or_finetune2.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/llm_asr/infer_speech2text.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/monotonic_aligner/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer-zh-spk/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/export.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer/infer_from_local.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer_streaming/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer_streaming/export.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/paraformer_streaming/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/export.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/infer_from_local.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws/path.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/export.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/infer_from_local.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sanm_kws_streaming/path.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/scama/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/seaco_paraformer/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/seaco_paraformer/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/sense_voice/finetune.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/uniasr/demo.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/whisper/infer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/whisper/infer_from_local.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/industrial_data_pretraining/whisper/infer_from_openai.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/wenetspeech/conformer/local/aishell_data_prep.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/wenetspeech/conformer/local/download_and_untar.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/examples/wenetspeech/conformer/run.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/fun_text_processing/install_pynini.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/deploy_tools/funasr-runtime-deploy-offline-cpu-en.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/deploy_tools/funasr-runtime-deploy-offline-cpu-zh.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/deploy_tools/funasr-runtime-deploy-online-cpu-zh.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/deploy_tools/install_docker.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/grpc/build.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/grpc/run_server.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/onnxruntime/third_party/download_ffmpeg.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/onnxruntime/third_party/download_onnxruntime.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/onnxruntime/third_party/gflags/src/gflags_completions.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/onnxruntime/third_party/kaldi/base/get_version.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/onnxruntime/third_party/openfst/_import_release.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/onnxruntime/third_party/openfst/ltmain.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/python/http/start_server.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/python/utils/test_cer.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/python/utils/test_rtf.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/run_server.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/run_server_2pass.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools/fst/collect_resource_file.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools/fst/compile_dict_token.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools/fst/make_decode_graph.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools/fst/parse_options.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools/fst/train_lms.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools/path.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools/train_compile_ngram.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/runtime/tools/utils/parse_options.sh
/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/recognize_english_speech.sh
(Open file: /GitTaskBench/run_asr.py)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:48:37,659 - INFO - swea-agent - ========================= STEP 15 =========================
2025-05-12 15:48:37,672 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:48:46,559 - INFO - swea-lm - Response: ModelResponse(id='0217470361177118ce1e7042c8a3994a70c7ec0e7dd433f171b0c', created=1747036126, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The repository contains many shell scripts, but the most relevant one for our task is `/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/recognize_english_speech.sh`, as it seems to be designed for speech recognition. Let's open this script to understand how it works.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"path":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/recognize_english_speech.sh"}', name='open'), id='call_ap18xo7xdz3zx0ixuu80qfkl', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=108, prompt_tokens=19891, total_tokens=19999, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:48:46,568 - INFO - swea-agent - 💭 THOUGHT
The repository contains many shell scripts, but the most relevant one for our task is `/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/recognize_english_speech.sh`, as it seems to be designed for speech recognition. Let's open this script to understand how it works.

🎬 ACTION
open "/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/recognize_english_speech.sh"
2025-05-12 15:48:47,070 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/recognize_english_speech.sh (23 lines total)]
1:
2:#!/bin/bash
3:# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
4:#  MIT License  (https://opensource.org/licenses/MIT)
5:
6:# Input and output paths
7:input="/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_02/input/FunASR_02_input.mp3"
8:output_dir="/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_02"
9:
10:# Model for English speech recognition
11:model="iic/speech_whisper-large_asr_en"
12:
13:device="cpu"  # Use CPU for inference
14:
15:# Ensure output directory exists
16:mkdir -p "${output_dir}"
17:
18:# Perform speech recognition
19:python -m funasr.bin.inference \
20:++model="${model}" \
21:++input="${input}" \
22:++output_dir="${output_dir}" \
23:++device="${device}"
(Open file: /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR/recognize_english_speech.sh)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:48:47,096 - INFO - swea-agent - ========================= STEP 16 =========================
2025-05-12 15:48:47,108 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:48:55,995 - INFO - swea-lm - Response: ModelResponse(id='0217470361271440b649dab7ede5cdaee14259c4eaf92dccc6fb9', created=1747036135, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The `recognize_english_speech.sh` script is designed to perform speech recognition on an English audio file. However, our input audio file is in Chinese, so we need to modify the script to use a model suitable for Chinese speech recognition.\n\n### Step 1: Modify the Script\nLet's create a new script called `recognize_chinese_speech.sh` that uses a Chinese speech recognition model.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"filename":"recognize_chinese_speech.sh"}', name='create'), id='call_jyo731b7kv8x2w0bw6xs0oz2', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=106, prompt_tokens=19607, total_tokens=19713, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:48:56,003 - INFO - swea-agent - 💭 THOUGHT
The `recognize_english_speech.sh` script is designed to perform speech recognition on an English audio file. However, our input audio file is in Chinese, so we need to modify the script to use a model suitable for Chinese speech recognition.

### Step 1: Modify the Script
Let's create a new script called `recognize_chinese_speech.sh` that uses a Chinese speech recognition model.

🎬 ACTION
create recognize_chinese_speech.sh
2025-05-12 15:48:56,523 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: recognize_chinese_speech.sh (1 lines total)]
1:
(Open file: /GitTaskBench/recognize_chinese_speech.sh)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:48:56,548 - INFO - swea-agent - ========================= STEP 17 =========================
2025-05-12 15:48:56,561 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:49:15,585 - INFO - swea-lm - Response: ModelResponse(id='0217470361365980b649dab7ede5cdaee14259c4eaf92dc3b4e24', created=1747036155, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="Now, let's insert the modified script content into `recognize_chinese_speech.sh`. We'll use the `speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch` model for Chinese speech recognition.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"text":"#!/bin/bash\\n# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.\\n#  MIT License  (https://opensource.org/licenses/MIT)\\n\\n# Input and output paths\\ninput=\\"/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav\\"\\noutput_dir=\\"/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01\\"\\n\\n# Model for Chinese speech recognition\\nmodel=\\"iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\\"\\n\\ndevice=\\"cpu\\"  # Use CPU for inference\\n\\n# Ensure output directory exists\\nmkdir -p \\"${output_dir}\\"\\n\\n# Perform speech recognition\\npython -m funasr.bin.inference \\\\\\n++model=\\"${model}\\" \\\\\\n++input=\\"${input}\\" \\\\\\n++output_dir=\\"${output_dir}\\" \\\\\\n++device=\\"${device}\\""}', name='insert'), id='call_ffezojsywsz1wbvvl0wl9o8u', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=324, prompt_tokens=19731, total_tokens=20055, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:49:15,595 - INFO - swea-agent - 💭 THOUGHT
Now, let's insert the modified script content into `recognize_chinese_speech.sh`. We'll use the `speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch` model for Chinese speech recognition.

🎬 ACTION
insert '#!/bin/bash
# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
#  MIT License  (https://opensource.org/licenses/MIT)

# Input and output paths
input="/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
output_dir="/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"

# Model for Chinese speech recognition
model="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"

device="cpu"  # Use CPU for inference

# Ensure output directory exists
mkdir -p "${output_dir}"

# Perform speech recognition
python -m funasr.bin.inference \
++model="${model}" \
++input="${input}" \
++output_dir="${output_dir}" \
++device="${device}"'
2025-05-12 15:49:16,113 - INFO - swea-agent - 🤖 MODEL INPUT
👋 INFO     This is SWE-agent version 1.0.1                                     
            (hash='aa4e8ea1611dad2220950cc5afb30aff17932b41') with SWE-ReX      
            version 1.2.1 (rex_hash='unavailable').                             
[File: /GitTaskBench/recognize_chinese_speech.sh (23 lines total)]
1:
2:#!/bin/bash
3:# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
4:#  MIT License  (https://opensource.org/licenses/MIT)
5:
6:# Input and output paths
7:input="/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
8:output_dir="/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
9:
10:# Model for Chinese speech recognition
11:model="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
12:
13:device="cpu"  # Use CPU for inference
14:
15:# Ensure output directory exists
16:mkdir -p "${output_dir}"
17:
18:# Perform speech recognition
19:python -m funasr.bin.inference \
20:++model="${model}" \
21:++input="${input}" \
22:++output_dir="${output_dir}" \
23:++device="${device}"
(Open file: /GitTaskBench/recognize_chinese_speech.sh)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:49:16,141 - INFO - swea-agent - ========================= STEP 18 =========================
2025-05-12 15:49:16,154 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:49:27,193 - INFO - swea-lm - Response: ModelResponse(id='02174703615627016b977401f4df41f54664316aeb6668e40fbae', created=1747036167, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='The script `recognize_chinese_speech.sh` is now ready. It will:\n1. Use the `speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch` model for Chinese speech recognition.\n2. Process the input audio file (`FunASR_01_input.wav`).\n3. Save the transcription result to the specified output directory (`/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01`).\n\n### Next Steps:\n1. **Run the Script**: Execute the script to perform speech recognition.', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"command":"bash recognize_chinese_speech.sh"}', name='bash'), id='call_zrjcjbxlq0zfpxyle29jv7vk', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=155, prompt_tokens=19897, total_tokens=20052, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:49:27,202 - INFO - swea-agent - 💭 THOUGHT
The script `recognize_chinese_speech.sh` is now ready. It will:
1. Use the `speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch` model for Chinese speech recognition.
2. Process the input audio file (`FunASR_01_input.wav`).
3. Save the transcription result to the specified output directory (`/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01`).

### Next Steps:
1. **Run the Script**: Execute the script to perform speech recognition.

🎬 ACTION
bash recognize_chinese_speech.sh
2025-05-12 15:49:27,500 - INFO - swea-agent - 🤖 MODEL INPUT
/usr/local/bin/python: Error while finding module specification for 'funasr.bin.inference' (ModuleNotFoundError: No module named 'funasr')
(Open file: /GitTaskBench/recognize_chinese_speech.sh)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:49:27,530 - INFO - swea-agent - ========================= STEP 19 =========================
2025-05-12 15:49:27,543 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:49:38,153 - INFO - swea-lm - Response: ModelResponse(id='021747036167577d9f2b6f781bd0539f58fa26888d28880307dc4', created=1747036178, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content="The error indicates that the `funasr` module is not installed in the current environment. Since we cannot install packages in this environment, we need to find an alternative way to run the script or use a different approach.\n\n### Alternative Approach:\n1. **Check for Pre-built Executables**: The FunASR repository might have pre-built executables or scripts that can be run directly without requiring the `funasr` module.\n\n2. **Locate Pre-built Executables**: Let's search for pre-built executables in the FunASR repository.", role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{"file_name":"*.bin", "dir":"/data/data/agent_test_codebase/GitTaskBench/code_base/FunASR"}', name='find_file'), id='call_h4gkws06kh7qdl9eveot6ta3', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=157, prompt_tokens=20050, total_tokens=20207, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:49:38,164 - INFO - swea-agent - 💭 THOUGHT
The error indicates that the `funasr` module is not installed in the current environment. Since we cannot install packages in this environment, we need to find an alternative way to run the script or use a different approach.

### Alternative Approach:
1. **Check for Pre-built Executables**: The FunASR repository might have pre-built executables or scripts that can be run directly without requiring the `funasr` module.

2. **Locate Pre-built Executables**: Let's search for pre-built executables in the FunASR repository.

🎬 ACTION
find_file '*.bin' /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
2025-05-12 15:49:38,443 - INFO - swea-agent - 🤖 MODEL INPUT
No matches found for "*.bin" in /data/data/agent_test_codebase/GitTaskBench/code_base/FunASR
(Open file: /GitTaskBench/recognize_chinese_speech.sh)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:49:38,480 - INFO - swea-agent - ========================= STEP 20 =========================
2025-05-12 15:49:38,491 - WARNING - swea-lm - No max input tokens found for model 'openai/deepseek-v3'. If you are using a local model, you can set `max_input_token` in the model config to override this.
2025-05-12 15:49:48,848 - INFO - swea-lm - Response: ModelResponse(id='021747036178527854170b95bb3319d72e46867b5c22f89be3bca', created=1747036188, model='deepseek-v3', object='chat.completion', system_fingerprint='', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content='No pre-built executables were found. Given the constraints of the environment, we cannot proceed further with the current approach. \n\n### Final Steps:\n1. **Summarize the Issue**: The task requires the `funasr` module, which is not available in the current environment. Without the ability to install the module, we cannot complete the task as described.\n\n2. **Suggest Next Steps**: \n   - If possible, the `funasr` module should be installed in the environment.\n   - Alternatively, the task could be performed in an environment where the `funasr` module is already installed.\n\nSince we cannot proceed further, we will conclude the task here.', role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='submit'), id='call_jqp0jurhq3zrtjrk3wvlbixi', type='function')], function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=150, prompt_tokens=16004, total_tokens=16154, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, text_tokens=None), prompt_tokens_details=None), service_tier='default')
2025-05-12 15:49:48,856 - INFO - swea-agent - 💭 THOUGHT
No pre-built executables were found. Given the constraints of the environment, we cannot proceed further with the current approach. 

### Final Steps:
1. **Summarize the Issue**: The task requires the `funasr` module, which is not available in the current environment. Without the ability to install the module, we cannot complete the task as described.

2. **Suggest Next Steps**: 
   - If possible, the `funasr` module should be installed in the environment.
   - Alternatively, the task could be performed in an environment where the `funasr` module is already installed.

Since we cannot proceed further, we will conclude the task here.

🎬 ACTION
submit
2025-05-12 15:49:49,441 - INFO - swea-agent - Found submission: diff --git a/config.yaml b/config.yaml
new file mode 100644
index 00000000..50138e92
--- /dev/null
+++ b/config.yaml
@@ -0,0 +1,3 @@
+
+input: /data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav
+model: speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch
\ No newline at end of file
diff --git a/recognize_chinese_speech.sh b/recognize_chinese_speech.sh
new file mode 100644
index 00000000..eb240bf4
--- /dev/null
+++ b/recognize_chinese_speech.sh
@@ -0,0 +1,23 @@
+
+#!/bin/bash
+# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
+#  MIT License  (https://opensource.org/licenses/MIT)
+
+# Input and output paths
+input="/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
+output_dir="/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
+
+# Model for Chinese speech recognition
+model="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
+
+device="cpu"  # Use CPU for inference
+
+# Ensure output directory exists
+mkdir -p "${output_dir}"
+
+# Perform speech recognition
+python -m funasr.bin.inference \
+++model="${model}" \
+++input="${input}" \
+++output_dir="${output_dir}" \
+++device="${device}"
\ No newline at end of file
diff --git a/run_asr.py b/run_asr.py
new file mode 100644
index 00000000..400701ba
--- /dev/null
+++ b/run_asr.py
@@ -0,0 +1,36 @@
+
+#!/usr/bin/env python3
+# -*- encoding: utf-8 -*-
+# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
+#  MIT License  (https://opensource.org/licenses/MIT)
+
+from funasr import AutoModel
+import os
+
+# Define input and output paths
+input_audio = "/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
+output_dir = "/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
+
+# Ensure output directory exists
+os.makedirs(output_dir, exist_ok=True)
+
+# Initialize the model
+model = AutoModel(
+    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
+    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
+    vad_kwargs={"max_single_segment_time": 60000},
+    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
+)
+
+# Perform speech recognition
+result = model.generate(
+    input=input_audio,
+    cache={},
+)
+
+# Save the result to a file
+output_file = os.path.join(output_dir, "output.txt")
+with open(output_file, "w") as f:
+    f.write(str(result))
+
+print(f"Speech recognition completed. Result saved to {output_file}")
\ No newline at end of file

2025-05-12 15:49:49,450 - INFO - swea-agent - 🤖 MODEL INPUT
diff --git a/config.yaml b/config.yaml
new file mode 100644
index 00000000..50138e92
--- /dev/null
+++ b/config.yaml
@@ -0,0 +1,3 @@
+
+input: /data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav
+model: speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch
\ No newline at end of file
diff --git a/recognize_chinese_speech.sh b/recognize_chinese_speech.sh
new file mode 100644
index 00000000..eb240bf4
--- /dev/null
+++ b/recognize_chinese_speech.sh
@@ -0,0 +1,23 @@
+
+#!/bin/bash
+# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
+#  MIT License  (https://opensource.org/licenses/MIT)
+
+# Input and output paths
+input="/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
+output_dir="/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
+
+# Model for Chinese speech recognition
+model="iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
+
+device="cpu"  # Use CPU for inference
+
+# Ensure output directory exists
+mkdir -p "${output_dir}"
+
+# Perform speech recognition
+python -m funasr.bin.inference \
+++model="${model}" \
+++input="${input}" \
+++output_dir="${output_dir}" \
+++device="${device}"
\ No newline at end of file
diff --git a/run_asr.py b/run_asr.py
new file mode 100644
index 00000000..400701ba
--- /dev/null
+++ b/run_asr.py
@@ -0,0 +1,36 @@
+
+#!/usr/bin/env python3
+# -*- encoding: utf-8 -*-
+# Copyright FunASR (https://github.com/alibaba-damo-academy/FunASR). All Rights Reserved.
+#  MIT License  (https://opensource.org/licenses/MIT)
+
+from funasr import AutoModel
+import os
+
+# Define input and output paths
+input_audio = "/data/data/agent_test_codebase/GitTaskBench/queries/FunASR_01/input/FunASR_01_input.wav"
+output_dir = "/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/FunASR_01"
+
+# Ensure output directory exists
+os.makedirs(output_dir, exist_ok=True)
+
+# Initialize the model
+model = AutoModel(
+    model="iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
+    vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
+    vad_kwargs={"max_single_segment_time": 60000},
+    punc_model="iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
+)
+
+# Perform speech recognition
+result = model.generate(
+    input=input_audio,
+    cache={},
+)
+
+# Save the result to a file
+output_file = os.path.join(output_dir, "output.txt")
+with open(output_file, "w") as f:
+    f.write(str(result))
+
+print(f"Speech recognition completed. Result saved to {output_file}")
\ No newline at end of file

(Open file: /GitTaskBench/recognize_chinese_speech.sh)
(Current directory: /GitTaskBench)
bash-$
2025-05-12 15:49:49,485 - INFO - swea-agent - Trajectory saved to /data/code/agent_new/SWE-agent/trajectories/i-youwang/default__openai/deepseek-v3__t-0.00__p-1.00__c-0.00___2dc60e/2dc60e/2dc60e.traj
2025-05-12 15:49:49,499 - INFO - swea-run - Done
2025-05-12 15:49:49,500 - INFO - swea-env - Beginning environment shutdown...
