{"model_name_or_path": "deepseek-v3__t-0.00__p-1.00__c-0.00___42268c", "instance_id": "42268c", "model_patch": "diff --git a/custom_config.yaml b/custom_config.yaml\nnew file mode 100644\nindex 00000000..25344643\n--- /dev/null\n+++ b/custom_config.yaml\n@@ -0,0 +1,19 @@\n+\n+# Custom configuration for speech enhancement\n+\n+# Input audio file\n+input_path: \"/data/data/agent_test_codebase/GitTaskBench/queries/SpeechEnhance_01/input/SpeechEnhance_01_input.wav\"\n+\n+# Output directory\n+output_folder: \"/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/SpeechEnhance_01\"\n+\n+# Model configuration\n+model:\n+  name: \"sepformer\"\n+  source: \"speechbrain/sepformer-whamr-enhancement\"\n+  savedir: \"pretrained_models/sepformer-whamr-enhancement\"\n+\n+# Audio settings\n+sample_rate: 16000\n+save_audio: True\n+n_audio_to_save: 1\n\\ No newline at end of file\ndiff --git a/enhance_audio.py b/enhance_audio.py\nnew file mode 100644\nindex 00000000..719f8380\n--- /dev/null\n+++ b/enhance_audio.py\n@@ -0,0 +1,18 @@\n+\n+from speechbrain.inference.separation import SepformerSeparation as separator\n+import torchaudio\n+\n+# Define paths\n+input_path = \"/data/data/agent_test_codebase/GitTaskBench/queries/SpeechEnhance_01/input/SpeechEnhance_01_input.wav\"\n+output_path = \"/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/SpeechEnhance_01/output.wav\"\n+\n+# Load the Sepformer model\n+model = separator.from_hparams(source=\"speechbrain/sepformer-whamr-enhancement\", savedir=\"pretrained_models/sepformer-whamr-enhancement\")\n+\n+# Enhance the audio\n+enhanced_speech = model.separate_file(path=input_path)\n+\n+# Save the enhanced audio\n+torchaudio.save(output_path, enhanced_speech[:, :, 0].detach().cpu(), 16000)\n+\n+print(\"Audio enhancement completed. Enhanced audio saved to:\", output_path)\n\\ No newline at end of file\ndiff --git a/run_enhancement.py b/run_enhancement.py\nnew file mode 100644\nindex 00000000..3d95c616\n--- /dev/null\n+++ b/run_enhancement.py\n@@ -0,0 +1,26 @@\n+\n+import os\n+import torchaudio\n+from speechbrain.inference.separation import SepformerSeparation as separator\n+\n+# Configuration\n+input_path = \"/data/data/agent_test_codebase/GitTaskBench/queries/SpeechEnhance_01/input/SpeechEnhance_01_input.wav\"\n+output_folder = \"/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/SpeechEnhance_01\"\n+model_source = \"speechbrain/sepformer-whamr-enhancement\"\n+model_savedir = \"pretrained_models/sepformer-whamr-enhancement\"\n+sample_rate = 16000\n+\n+# Load the Sepformer model\n+model = separator.from_hparams(\n+    source=model_source,\n+    savedir=model_savedir\n+)\n+\n+# Enhance the audio\n+enhanced_speech = model.separate_file(path=input_path)\n+\n+# Save the enhanced audio\n+output_path = os.path.join(output_folder, \"output.wav\")\n+torchaudio.save(output_path, enhanced_speech[:, :, 0].detach().cpu(), sample_rate)\n+\n+print(\"Audio enhancement completed. Enhanced audio saved to:\", output_path)\n\\ No newline at end of file\n"}