{"model_name_or_path": "default__claude-3-5-sonnet-20241022__t-0.00__p-1.00__c-3.00___4e1925", "instance_id": "4e1925", "model_patch": "diff --git a/extract_tables.py b/extract_tables.py\nnew file mode 100644\nindex 00000000..31dec8d9\n--- /dev/null\n+++ b/extract_tables.py\n@@ -0,0 +1,41 @@\n+\n+import pdfplumber\n+import pandas as pd\n+import os\n+\n+# Input and output paths\n+input_pdf = \"/data/data/agent_test_codebase/GitTaskBench/queries/PDFPlumber_02/input/PDFPlumber_02_input.pdf\"\n+output_dir = \"/data/data/agent_test_codebase/GitTaskBench/eval_automation/output/PDFPlumber_02\"\n+output_file = os.path.join(output_dir, \"output.csv\")\n+\n+# Create output directory if it doesn't exist\n+os.makedirs(output_dir, exist_ok=True)\n+\n+# Initialize an empty list to store all tables\n+all_tables = []\n+\n+# Open the PDF\n+with pdfplumber.open(input_pdf) as pdf:\n+    # Process only first two pages\n+    for page_num in range(min(2, len(pdf.pages))):\n+        page = pdf.pages[page_num]\n+        # Extract tables from the page\n+        tables = page.extract_tables()\n+        \n+        # Process each table\n+        for table in tables:\n+            # Convert table to DataFrame\n+            df = pd.DataFrame(table)\n+            # Add page number information\n+            df['Page_Number'] = page_num + 1\n+            all_tables.append(df)\n+\n+# If we found any tables\n+if all_tables:\n+    # Concatenate all tables\n+    final_df = pd.concat(all_tables, ignore_index=True)\n+    # Save to CSV\n+    final_df.to_csv(output_file, index=False)\n+    print(f\"Tables extracted and saved to {output_file}\")\n+else:\n+    print(\"No tables found in the first two pages of the PDF\")\n\\ No newline at end of file\n"}